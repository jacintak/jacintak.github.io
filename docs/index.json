[{"authors":["admin"],"categories":null,"content":"\r\rI want to know where animals live and how they persist in their environment. Traits are a focus of my work because traits are how organisms interact with their environment.\nMy research follows a general theme of understanding the mechanistic determinants of ecological and evolutionary patterns and the physiological niches of organisms, specifically of ectotherms. My interests lie at the intersection between ecology, evolutionary biology and climate adaptation.\nI answer these questions through an integrative combination of field observations, manipulative laboratory experiments and computer modelling in R, grounded within a theoretical framework, such as mechanistic niche models.\n","date":1625753100,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1625753100,"objectID":"d33c1cd8bead9ce2a6229ddb7fdca4a5","permalink":"https://jacintak.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I want to know where animals live and how they persist in their environment. Traits are a focus of my work because traits are how organisms interact with their environment.\nMy research follows a general theme of understanding the mechanistic determinants of ecological and evolutionary patterns and the physiological niches of organisms, specifically of ectotherms. My interests lie at the intersection between ecology, evolutionary biology and climate adaptation.","tags":null,"title":"Jacinta Kong","type":"authors"},{"authors":null,"categories":null,"content":"\r\rIntroduction\rStatsModels is an R package of learnr tutorials comprising two practicals on statistical modelling made for BUY22S01 Statistics and Computation at Trinity College Dublin. The package is distributed via GitHub. Each practical is for a 3 hour slot.\nThe aim of the practicals is to introduce statistical modelling. It uses functional responses (i.e.¬†Type II models, Holling‚Äôs disc equation) as background information.\nThere are two parts to the practical:\nIntroduction to statistical modelling\r\rConstructing a Type II model\rDesigning an experiment\rCollecting data\r\rData analysis using statistical models in R\r\rImporting data\rManipulating data\rConducting multiple linear regression\rVisualising data\r\r\rPart 1 requires students collect data by replicating Holling‚Äôs disc experiment with two predictor variables: prey density and jar type (lid/ no lid). This practical focuses on Type II models. Part 2 analyses the data using both additive and interactive multiple linear regression. Simple linear regressions (with one predictor variable) are not covered for time constraints.\nRemote version\rIt is possible to adapt this in-person practical to a remote version by getting students to collect data using a Scratch simulation of a Type II functional response. I have a Scratch model of one.\n\r\rSet up\rWe need to set up our computer to download the practical in R.\nFollow this checklist in order to make sure you are set up:\nHave you installed R version 4.0 or above? - if not, install/update R\r\rYou can check your R package version using R.Version()$version.string\r\rHave you installed RStudio version 1.0.136 or above? - if not install/update RStudio\r\rYou can check your RStudio version using RStudio.Version()$version\r\rHave you installed the following packages? - if not use install.packages(\"\u0026lt;name of package\u0026gt;\") to do so\r\rlearnr - needed to run the tutorials\rremotes - needed to install the tutorials\r\r\rIf everything works then you should see a Tutorials tab in one of your RStudio windows. There may already be tutorials listed there.\n\rInstalling the tutorials\rNow we need to install the tutorial. The tutorials are stored in a Package available on GitHub. You will only have to install the package once at the beginning.\nUse the following code:\nremotes::install_github(\u0026quot;jacintak/biostats\u0026quot;, dependencies = TRUE, build_vignettes = TRUE)\rIf you are asked to install any other packages, choose yes.\nIf you are asked to update any packages, press 1 for updating all of them.\nIf you are asked to install packages from source (i.e.¬†in a pop-up window) press no.\nIf the package installed properly, you should automatically see the tutorials in the Tutorial tab.\n\rRunning a tutorial\rYou should be able to run a tutorial from the Tutorial tab when you open RStudio without needing to do anything.\nMake sure it‚Äôs a tutorial from the StatsModels package.\nIf you click run tutorial, the tutorial will show up in the tab. You can click the ‚ÄúShow in new window‚Äù icon to open it in another window. Press the ‚ÄúHome‚Äù icon to return to the Tutorials tab.\nIf that doesn‚Äôt work use this code and the tutorial will open in another window or your browser:\nlearnr::run_tutorial(\u0026quot;\u0026lt;insert name of the tutorial to run\u0026gt;\u0026quot;, package = \u0026quot;StatsModels\u0026quot;)\rQuit a tutorial by pressing the ‚ÄúStop‚Äù icon.\n\r","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"17eecd051902cb6c28176e1e35bffd2a","permalink":"https://jacintak.github.io/project/statistical-modelling/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/project/statistical-modelling/","section":"project","summary":"Learning statitical modelling with functional responses","tags":["teaching","R stats","code"],"title":"Statistical Modelling Practicals","type":"project"},{"authors":[],"categories":["code"],"content":"\r\rI love gifs.\nGifs are great for showing how data changes over time or just for putting something engaging in a presentation. When I was working on modelling insect phenology I wanted to create a gif of how insects hatch throughout the year across Australia for my presentations. Making gifs in R has improved a little since then so here‚Äôs a quick guide to making gifs. I won‚Äôt cover interactive plots (e.g.¬†plotly).\nLooping through images\rBasically this involves making lots of png images then looping through them. The package is animation which depends on ImageMagick so you will need to install ImageMagick first. I‚Äôve found it handy for sequentially showings layers of a raster (e.g.¬†where each layer is data over time).\nMake sure to install legacy functions when installing ImageMagick (e.g.¬†convert). You may need to tell R where to find ImageMagick using ani.options(convert = 'C:/ImageMagick-7.0.9-Q16/convert.exe') for where ever ImageMagick was installed.\nLet‚Äôs pretend we have a raster of soil temperature for one day where each layer (n = 24) is an hour of a day (soil_temp), like a raster from microclimOz.\nWe need to create our loop, then we can use animation::saveGIF to save our image.\nlibrary(animation)\rlibrary(raster)\rpal \u0026lt;- terrain.colors(10, rev = TRUE)\rbre \u0026lt;- round(seq(min(minValue(soil_temp))-1,max(maxValue(soil_temp))+1,length.out=10))\rsaveGIF({\rfor(i in 1:24){plot(soil_temp[[i]], main = i, col = pal, breaks = bre)}\r}, movie.name = \u0026quot;soil_temp.gif\u0026quot;, clean=T, convert = \u0026quot;convert\u0026quot;)\rTo make sure the colour scale is consistent throughout the loop:\n\rI‚Äôve defined a fixed colour scale (pal) using the base palette terrain.colours and reversed the scale so that higher temperatures are green. Note that the terrain colour palette isn‚Äôt great for colour blindness.\rI‚Äôve created my own colour scale (bre) by manually defining the breaks in the colour scale based on the minimum and maximum temperatures in the entire raster dataset. Plus some wiggle room on either side.\r\rIf I didn‚Äôt manually define the colour scale, then each image in the gif will use its own automatically generated scale and the colours will be inconsistent.\nNote the use of curly brackets to call an independent line of R code within code (the loop within saveGIF).\nThe benefit of animation is that it works with any type of image in R and is basically a wrapper for ImageMagick, unlike gganimate. You could also use ImageMagick in the command line.\n\rGradually showing data\rThis is easily done using ggplot2 and gganimate. ImageMagick isn‚Äôt needed (a different engine is used) but this method is limited to ggplot objects.\nI have some heart rate data demonstrating the mammalian diving reflex that I will use as an example. I imported the data from my Apple Watch into R that you can read about at the link. Then, I made a gif for my lectures using gganimate:\nlibrary(gganimate) # loading just gganimate will also load ggplot2 for you\rlibrary(tidyverse)\rhr_plot \u0026lt;- heart_rate %\u0026gt;%\rfilter(time \u0026gt; \u0026quot;2020-10-17 11:00:34\u0026quot; \u0026amp; time \u0026lt; \u0026quot;2020-10-17 11:13:00\u0026quot;) %\u0026gt;% ggplot(aes(time, value)) +\r# Dive 1\rannotate(\u0026quot;rect\u0026quot;, fill = \u0026quot;lightgrey\u0026quot;, alpha = 0.7, xmin = as.POSIXct(\u0026quot;2020-10-17 11:05:00\u0026quot;), xmax = as.POSIXct(\u0026quot;2020-10-17 11:05:30\u0026quot;),\rymin = -Inf, ymax = Inf) +\r# Dive 2\rannotate(\u0026quot;rect\u0026quot;, fill = \u0026quot;lightgrey\u0026quot;, alpha = 0.7, xmin = as.POSIXct(\u0026quot;2020-10-17 11:07:12\u0026quot;), xmax = as.POSIXct(\u0026quot;2020-10-17 11:07:50\u0026quot;),\rymin = -Inf, ymax = Inf) +\rgeom_point(aes(group = seq_along(time))) +\rgeom_line() +\rannotate(\u0026quot;text\u0026quot;, label = \u0026quot;Dives\u0026quot;, x = as.POSIXct(\u0026quot;2020-10-17 11:10\u0026quot;), y = 75) +\rannotate(\u0026quot;rect\u0026quot;, fill = \u0026quot;lightgrey\u0026quot;, alpha = 0.7, xmin = as.POSIXct(\u0026quot;2020-10-17 11:10:40\u0026quot;), xmax = as.POSIXct(\u0026quot;2020-10-17 11:11:10\u0026quot;),\rymin = 73, ymax = 77) +\rtheme_classic() +\rlabs(x = \u0026quot;Time\u0026quot;, y = expression(\u0026quot;Heart rate \u0026quot;(\u0026quot;Beats min\u0026quot;^-1))) +\rscale_x_datetime() + # time is already a POSIXct format\rylim(c(50, 125)) +\rtransition_reveal(time) +\renter_fade()\ranimate(plot = hr_plot,\rnframes = 100,\rfps = 10,\rend_pause = 10,\rheight = 600, width =600, res = 100)\rI‚Äôve split this into two parts. Lets break this down:\nMake the heart rate graph (hr_plot). My heart rate data is saved in a variable called heart_rate.\rI have trimmed the data (dplyr::filter) then plotted heart rate over time (lines and points).\rI have annotated the graph with grey rectangles (annotate(\"rect\")) to indicate diving periods.\rI created a legend using annotate for text and another little grey rectangle.\rUsed expression for scientific notation in my axis labels.\rFormatted the x axis as a date time axis (scale_x_datetime). Not critical here.\rtransition_reveal and enter_fade are gganimate functions that describe how the data is revealed. Here I‚Äôm saying reveal along the x axis. This may take some time to render when you call the plot.\r\ranimate is the main function to create the animation.\r\rI defined the number of frames, the speed (frames per second), how long to pause the gif at the last frame, and the dimensions.\rUse anim_save to save your gif.\r\r\rHere‚Äôs proof I am a mammal:\rThere are other types of transitions included in gganimate. There is a handy cheatsheet too.\nHappy animating!\n\r","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"7fde4ee379305fae8ab11ee765514b42","permalink":"https://jacintak.github.io/post/2021-11-01-gifs-in-r/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/post/2021-11-01-gifs-in-r/","section":"post","summary":"Two ways of making gifs in R using {animation} and {gganimate}","tags":["R stats","code"],"title":"Gifs keep on giving","type":"post"},{"authors":null,"categories":["code"],"content":"\r\rNB: This was originally a tutorial given to Space Lunch members on 6th October 2021. This is an adapted version. The original version can be found on the Project page.\nIntroduction\rThis is going to be an introduction to a simple workflow for spatial data in R using rasters. I will assume you have some basic knowledge about spatial analyses and co-ordinate systems. This is not meant to be a documentation of the full suite of spatial analysis available in R. Some simple ways of plotting data is covered.\nRasters are stored spatial data in a gridded format.\n\rEach grid cell contains a single value. E.g. temperature, elevation, species richness\rOften stored in three dimensions (e.g.¬†latitude, longitude and time).\rThe main R package for handling rasters is raster. It‚Äôs a base package.\r\rWe will consider a common workflow of associating rasters with spatial point data (e.g.¬†lat and long).\rI will be sticking to base R throughout.\n\rIntroducing rasters\rLoading from file\rRasters can be acquired from a range of sources, such as government agencies. There are also R packages to interface directly with online databases but for another time. Often they are saved as an nc file (network Common Data Form) that is imported as a raster with layers and assigned a spatial projection. You‚Äôll see below that other dependent packages are loaded with raster but you won‚Äôt need to load each one manually.\nYou can load a raster from a local nc file using the function raster::brick. The :: denotes calling a function from a specific package without loading it with library. Good for quick and dirty functions you won‚Äôt use frequently, bad if you are using the package multiple times.\nmy_raster \u0026lt;- brick(\u0026quot;raster_data.nc\u0026quot;)\rI will cheat and use the built in function in raster to query WorldClim for mean annual temperature.\nlibrary(raster)\r## Loading required package: sp\rtemp \u0026lt;- getData(\u0026quot;worldclim\u0026quot;,var=\u0026quot;bio\u0026quot;,res=10)\r\rSubsetting rasters\rSubset rasters by layers using basic square bracket subsetting for lists.\ntemp \u0026lt;- temp[[1]] # Subset only the first layer - mean annual temperature\rHere I have selected mean annual temperature since we do not need the other variables.\n\rPlot rasters\rWe can use the basic plot function to view the raster data.\nplot(temp)\r\rFigure 1: Average annual temperature\r\rThe default colour scale is horrendous so we will change it to the viridis scale. Here‚Äôs an example of using ::. I don‚Äôt need the entire viridis package. This is to make a continuous colour palette of 20 colours. And add a title to the graph.\nplot(temp, main = \u0026quot;Mean annual temperature\u0026quot;, col = viridis::viridis(n = 20))\r\rFigure 2: That‚Äôs better\r\rThere‚Äôs one last issue to deal with before this data is ready. WorldClim stores temperature data multiplied by 10 for space saving so we need to divide by 10.\n\rManipulating rasters\rRasters can be manipulated by base functions. E.g. addition or subtraction between rasters or layers. There are many other functions for analysing rasters and doing spatial analysis (e.g.¬†interpolation) but we won‚Äôt cover that here.\ntemp \u0026lt;- temp/10\rplot(temp, main = \u0026quot;Mean annual temperature\u0026quot;, col = viridis::viridis(n = 20))\r\rFigure 3: That‚Äôs much much better\r\r\r\rSpatial point data\rI usually encounter spatial data in the form of decimal latitude and longitudes representing species occurrences or sampling sites. You may already have these data from your own work but for demonstration purposes I will show how to query an online database to get species distribution points from GBIF. This requires an Internet connection and the R package rgbif.\nLet‚Äôs query GBIF occurrence points for an widespread bird: The house sparrow (Passer domesticus).\n\rYou need the unique identification key for the species you want. name_suggest can help with that so you don‚Äôt have to manually search GBIF.\rThe data comes as a list with some metadata. .$data is the actual occurrence records. The dot . is a placeholder meaning it represents an R variable (e.g.¬†a dataframe). This is commonly used in tidyverse and piping via magrittr. It is also a cheat‚Äôs way of using base functions within a pipe.\rCo-ordinates are stored as decimalLatitude and decimalLongitude. I‚Äôve removed any missing values.\r\rlibrary(rgbif)\r# get ID key for bird\rbird_key \u0026lt;- name_suggest(q =\u0026quot;Passer domesticus\u0026quot;, rank=\u0026#39;species\u0026#39;)$data$key[1]\r# get occurence points\rbird_points \u0026lt;- occ_search(taxonKey = bird_key) # Get all records, max 500 (see variable limit)\r# exclude metadata\rbird_points \u0026lt;- bird_points$data\r# remove NA latitude or longitude\rbird_points \u0026lt;- bird_points[!is.na(bird_points$decimalLatitude),]\rSince I‚Äôve only searched for one species, the workflow is simple. If I wanted multiple species I would have to use lists and a function like sapply. See help file for occ_search for an example. Avoid for loops.\nPlot spatial data\rLet‚Äôs look at the global distribution of points. I will use the base maps package for a simple, low resolution and unprojected world map in R (not recommended for more professional output). The maps package can also be used in ggplot2 via borders(database = \"world\", fill = NA) or geom_polygon(data = map_data(\"world\"), aes(x=long, y = lat, group = group), fill = NA, col= 1); coord_map() may help in these cases.\nlibrary(maps)\rmap(\u0026quot;world\u0026quot;) # get basic world map\rtitle(main = \u0026quot;The distribution of house sparrow\u0026quot;) # plot title\rpoints(decimalLatitude ~ decimalLongitude, bird_points, pch = 16, col = 2) # plot points\rlegend(x = -150, y= -50, legend = \u0026quot;occurence\u0026quot;, pch = 16, col = 2, bty = \u0026quot;n\u0026quot;)\rWe see that points come mainly from around northern Europe.\nFor more advanced mapping in R check out ggmaps, which can interface with Open Street Maps (free) and Google Maps (for a fee), and osmdata, which interfaces directly with OSM and allows you to customise which features to include - check out the related tutorial about mapping cities in R in the Space Club folder or online.\n\r\rPutting it all together\rNow we have all the data we need, let‚Äôs combine the datasets and plot the occurrence data with the temp raster.\nplot(temp, main = \u0026quot;Mean annual temperature\u0026quot;, col = viridis::viridis(n = 20)) # temp\rpoints(decimalLatitude ~ decimalLongitude, bird_points, pch = 16, col = 1) # bird\r\rFigure 4: The distribution of sparrows with mean annual temperature\r\rLet‚Äôs do some simple extraction of data.\nWhat range of temperatures do house sparrows live in?\rWe can use our new species distribution points to query the raster and extract values corresponding with the occurrence points. The function to query a raster is raster::extract. The same can be used within tidyverse via mutate.\n# Get temp\rtemps \u0026lt;- extract(temp, SpatialPoints(cbind(bird_points$decimalLongitude, bird_points$decimalLatitude)), method = \u0026quot;bilinear\u0026quot;)\r# Add new column\rbird_temps \u0026lt;- cbind(bird_points, temps) # Remove missing temps\rbird_temps \u0026lt;- bird_temps[!is.na(bird_temps$temps),]\rmethod = \"bilinear\" tells the function to interpolate the average of the nearest 4 cells around the spatial point. This is like a mini version of buffer which will interpolate values within a buffer around a point. If spatial accuracy is not paramount (like here where we have a global scale raster), then this method might reduce the chance of extracting a NA value. The default is to query the exact coordinate.\nOur final dataset contains 500 observations.\nMissing data at this stage could be from a mismatch between the accuracy of the spatial points and the resolution of the raster. Or plain errors in the spatial coordinates.\nNow we can plot the distribution of temperatures:\nhist(bird_temps$temps, main = \u0026quot;Temperature distribution of house sparrows\u0026quot;)\rWe can see they live between -2.7 and 11.6 ¬∞C.\nFinally, we can plot the relationship between temperature and latitude:\nplot(temps ~ decimalLatitude, bird_temps, pch = 16)\rEnd\n\r\r","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"1dd2b182f0dd969ff329299f81c4187e","permalink":"https://jacintak.github.io/post/spatial-data/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/post/spatial-data/","section":"post","summary":"A basic workflow with rasters and spatial points","tags":["code","R stats"],"title":"An introduction to spatial data in R","type":"post"},{"authors":null,"categories":["code"],"content":"\r\rEarlier this year I wrote about learning to forego for loops for apply functions in R. I‚Äôm continuing this journey to replace for loops with purrr. I‚Äôll be honest and say that my main motivation for learning purrr is the package name üê±. purrr is a package that does the same things as mapply and lapply; to apply a function over listed data and also has useful functions for manipulating lists and functional programming.\nObjectively, the functionality of purrr is not that different to base functions. There‚Äôs an understandable learning curve and resulting benefit when going from for loops to apply functions, but there‚Äôs diminishing return on going from apply to purrr unless you fully leverage the shortcuts of tidyverse syntax (which I have not). The main advantage of purrr is that it uses the tidyverse syntax and pipes. Overall, I don‚Äôt think there‚Äôs a huge benefit for using purrr over base, unlike for example the advantages of using ggplot2 over base for graphing, but if your code is already written in tidyverse then it makes sense to stick to it and have clear and consistent code (if you are used to reading tidyverse syntax).\nIf you really want to stay on the tidyverse train you can skip learning apply and jump straight to purrr but I‚Äôm a fan of using as fewer dependencies as possible and knowing the base R way. There are lots of detailed tutorials about purrr and it‚Äôs functions, like this one that discusses the differences with base functions so I recommend checking those out. If you‚Äôre already familiar with the tidyverse syntax then purrr is no different.\nHere are some things I‚Äôve learnt about purrr for applying functions to listed data.\nlapply\rlapply takes one argument (data) and applies a function to it. As I found earlier, it‚Äôs quite a simple case and doesn‚Äôt suit more complex datasets I usually work with. The purrr equivalent is map.\nOne of the advantages of purrr is that it you can specify the format of the output. That is, lapply and map takes a list and produces a list, but map_* where * are a range of output types will give that output type. For example, map_chr will take a list and produce a character vector. This is handy because it skips an intermediate step to transform your resulting list into your desired output format, such as using do.call to turn a list into a data frame.\nAn example\rLet‚Äôs use the same code as the previous post:\n# some data to use as a list\rloop_data \u0026lt;- data.frame(col1 = c(11:15), col2 = c(20:24))\r# define variable to change\ra \u0026lt;- seq(0.2, 1, 0.2)\rAs before, loop_data is a data frame with two numeric columns (col1 \u0026amp; col2). We technically won‚Äôt use loop_data$col2 but it‚Äôs there to create a 5x2 data frame. a is a variable that we need for our function with 5 values.\nWe want to add each element of a to loop_data$col1 and save that in a new column loop_data$col1a. We will also add a as a column in loop_data just so we can keep track of which value was used to calculate col1a. So the final output should have 25 rows (5 observations in loop_data x 5 values of a) and 4 columns (col1, col2, col1a, a).\nNow let‚Äôs use map to do the same thing we did with lapply but using tidyverse and pipes üõÅ\nloop_data %\u0026gt;% expand_grid(., a) %\u0026gt;% # expand to include all crossed combinations\rgroup_split(a) %\u0026gt;% # split into lists by the value of a for nested lists\rmap_dfr(., function(x){\rx$col1a \u0026lt;- x$col1 + x$a\rreturn(x)\r}) %\u0026gt;% # apply the function to the list and return a data frame\rsummary(.) # show the summary\r## col1 col2 a col1a ## Min. :11 Min. :20 Min. :0.2 Min. :11.2 ## 1st Qu.:12 1st Qu.:21 1st Qu.:0.4 1st Qu.:12.4 ## Median :13 Median :22 Median :0.6 Median :13.6 ## Mean :13 Mean :22 Mean :0.6 Mean :13.6 ## 3rd Qu.:14 3rd Qu.:23 3rd Qu.:0.8 3rd Qu.:14.8 ## Max. :15 Max. :24 Max. :1.0 Max. :16.0\rIf you‚Äôre not familiar with piping this is what‚Äôs happening:\nThe first line is specifying our list loop_data to be sent down the pipe (%\u0026gt;%). Pipes are read sequentially and the output of one line is used as the input of the next line. This intermediate object is indicated by the dot (.). Sometimes the dot can be left out if the arguments are presented to the function in the expected order but I find it useful to type everything out when learning anyway so that it‚Äôs clear what the arguments are. The dot is particularly needed when using base functions within a pipe, as seen in the last line with summary(.) because these functions are expecting an argument that tidyverse functions know how to deal with.\rI use tidyr::expand_grid to create a data frame of all combinations of col1 and a. This has a benefit of adding a as a column.\rThen I use group_split to group the crossed data frame based on values of a. This produces a tibble which are essentially tidyverse lists. split is a base equivalent.\rThen I apply the actual function over the list and specify that I want the output to be a single data frame (the _dfr suffix). This is the equivalent of doing lapply and do.call in the same function.\rFinally I use the base R function summary to show the summary statistics of the result to check it works. There isn‚Äôt a tidyverse equivalent of summary so we must use the dot within the function.\r\rThe end result is exactly the same as the original lapply code. Here is the lapply function from the previous post to compare:\n# Prepare the answer list\rlapply_ans \u0026lt;- replicate(length(a), loop_data, simplify = FALSE)\r# add a column using mapply\rlapply_ans \u0026lt;- mapply(FUN = cbind, lapply_ans, \u0026quot;a\u0026quot; = a, SIMPLIFY = FALSE)\r# apply function\rlapply_ans \u0026lt;- lapply(lapply_ans, FUN = lapply_function)\r# merge to single data frame\rlapply_ans \u0026lt;- do.call(rbind, lapply_ans)\r# view the data\rsummary(lapply_ans)\r\rSide note:\rrerun(length(a), loop_data) behaves exactly the same as replicate(length(a), loop_data, simplify = FALSE) and is the tidyverse equivalent (unclear for how long according to the dev notes). Then you‚Äôll need to add a as a column, matching the order of the tibble and set the column names, e.g.¬†rerun(length(a), loop_data) %\u0026gt;% map2(a, bind_cols) %\u0026gt;% map(a=...3, rename).\n\rThe differences:\n\rI‚Äôve taken a slightly different approach. I define all possible combinations I want to use in the calculations then creating grouped lists.\rI specified the function within the pipe rather than named in the global environment like in the original post. It‚Äôs better to name the function if you‚Äôre using it multiple times but in this post I‚Äôm only using it once, so I‚Äôll get away with it.\r\rmap also allows formulas which for simple functions (like adding a constant to all values) will simplify the code and let\ryou use anonymous functions. I‚Äôm not used to the formula method of writing functions.\r\rInstead of 5 separate lines of code with the base version, in tidyverse we can do it in a pipe with 4 steps. But you notice that it‚Äôs not a huge difference between what the two approaches are doing. Still better than a for loop.\r\rWe skipped do.call by using map_dfr directly to return a data frame. I could also use map and transform the list into a\rdata frame separately.\r\r\r\rAnd another thing‚Ä¶\rWe need to prepare the input data so that it is crossed; which mean replicating our list across all combinations of col1 and a. expand_grid or similar as used above could be helpful for this, and the data frame could be split into nested lists for applying the function.\nTo contrast, this will only add matching rows of col1 and a together rather than all combinations:\nlist(loop_data$col1, a) %\u0026gt;%\rpmap_dfr(function(x, a) {\rdf \u0026lt;- data.frame(col1 = x,\ra = a,\rcol1a = x + a) # add answer to a new column\rreturn(df)\r})\r## col1 a col1a\r## 1 11 0.2 11.2\r## 2 12 0.4 12.4\r## 3 13 0.6 13.6\r## 4 14 0.8 14.8\r## 5 15 1.0 16.0\rSince map is the equivalent of lapply, then it also doesn‚Äôt take multiple inputs, which is why we added a as a column to loop_data. So we turn to mapply and its purrr equivalent.\n\r\rmapply\rThe purrr equivalent of mapply is pmap. Specifically, pmap allows for any number of arguments for the function. There is another function, map2 that accepts exactly two arguments but pmap is generalised to allow for more than two. As with map, there are variants with suffixes that specify what output format you want, such as a data frame (pmap_dfr).\nThe tidyverse website goes into the syntax differences between mapply and pmap in more detail.\nLet‚Äôs jump to the example using the same loop_function as the original post.\npmap\r# A function to add a value a to a data frame x\rloop_function \u0026lt;- function(x, a) {\rx$col1a \u0026lt;- x$col1 + a # add answer to a new column\rx$a \u0026lt;- a\rreturn(x)\r}\rloop_data %\u0026gt;% rerun(length(a), .) %\u0026gt;% # replicate the list to populate\rlist(a) %\u0026gt;% # define all variables for loop_function within a list\rpmap_dfr(loop_function) %\u0026gt;% # apply the function to the list and return a data frame\rmap_dfc(summary) # show the summary\r## # A tibble: 6 x 4\r## col1 col2 col1a a ## \u0026lt;table\u0026gt; \u0026lt;table\u0026gt; \u0026lt;table\u0026gt; \u0026lt;table\u0026gt;\r## 1 11 20 11.2 0.2 ## 2 12 21 12.4 0.4 ## 3 13 22 13.6 0.6 ## 4 13 22 13.6 0.6 ## 5 14 23 14.8 0.8 ## 6 15 24 16.0 1.0\rNow we don‚Äôt have to add a as a column to loop_data, we can specify a for the function. pmap takes a list of arguments for the function, hence we need a list containing both loop_data and a. Don‚Äôt make a list before adding it to the list of function arguments (i.e.¬†double list) because it won‚Äôt match the nth a variable with the nth element in the loop_data list, and match by rows within lists. For variety, I‚Äôve used map_dfc to call the function summary on the data, rather than summary(.). map_dfc will apply the function by columns instead of rows and produce a data frame.\nThe map2 equivalent is more concise than pmap for this simple example!\nloop_data %\u0026gt;% rerun(length(a), .) %\u0026gt;% map2_dfr(a, loop_function)\rHere is the original mapply example to compare:\n# Prepare the answer list\rmapply_ans \u0026lt;- replicate(length(a), loop_data, simplify = FALSE)\r# mapply function\rmapply_ans \u0026lt;- mapply(mapply_ans, FUN = loop_function, a = a, SIMPLIFY = FALSE)\r# merge to single data frame\rmapply_ans \u0026lt;- do.call(rbind, mapply_ans)\r# view the data\rsummary(mapply_ans)\rYou could also define loop_function as an anonymous function within pmap.\n\rMake sure the variables are used in the correct order. e.g.¬†loop_data %\u0026gt;% rerun(length(a), .) %\u0026gt;% map_dfr(loop_function, a) will run because you are passing a as a variable into loop_function, but it‚Äôs adding a by row within individual data frame rather than matching the nth element of the list. So it‚Äôs effectively replicating the data frame 5 times.\n\rThat‚Äôs it. There are many ways of doing the same thing with simple examples. Hope it helps you create purrrfectly sensible code to replace for loops and apply functions to lists.\n\r\r","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"6185c03b7b3350951a09ee17eaf6c2e8","permalink":"https://jacintak.github.io/post/purrr/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/post/purrr/","section":"post","summary":"Learning to use purrr","tags":["code","R stats"],"title":"Beyond the valley of intermediate competence","type":"post"},{"authors":null,"categories":null,"content":"\r\r\rWelcome to Statistics and Computation for Biologists\rWhy programming and computing?\r\rBasic computing terms\r\rDrives, Folders \u0026amp; Files\rDirectories\r\rWhy R?\rWhy RStudio?\r\rInstalling R and RStudio\r\rWindows\rMac\rLinux\rChromebook\r\rOpening R and RStudio for the first time\r\rUpdating R and packages\rCreating a script\rSetting up packages\rWorking directories\rChanging working directories\r\rLoading data\r\r.txt\r.csv\rCopying data\r\rTry it yourself\r\r\rChecking the data\r\rData structure\rSummarising data\r\rTips\rFinding help\rFinal checklist\r\r\rWelcome to Statistics and Computation for Biologists\rTraining to become a scientist can be broken down into two parts. First, there is content to learn - these are technical details or ‚Äúhow to‚Äù which come from textbooks, lectures or resources on the Internet.\nSecond, is learning how to define problems and how to solve them. You will see this in action throughout your degree. For example, is your R code not working? Work out why, what‚Äôs wrong and what to change to make it work.\nIn this module we aim to give you the tools and knowledge to solve your own data science problems. These skills will be important in your later studies or even your career.\nUse the following checklist to make sure you are prepared for this semester:\n\rDo you know how to navigate computer directories and addresses to find files or folders?\rDo you have R and RStudio installed on your computer?\rIs R up to date? (version 4.0 or above)\rDo you know how to set up scripts and directories in RStudio?\rDo you know how to import and export data into R in various formats?\r\rIf you‚Äôve answered no to any of the above questions, then continue on. Some of you may already have R and RStudio installed from previous modules - that‚Äôs great! Check that your version and packages are all up to date (Under the Packages tab, click Update). Even so, you can work through this document if you want to check everything works or you need a refresher.\n\rWhy programming and computing?\rWe care about teaching you programming and computing skills because they are important skills in the current workforce and are not to be taken for granted. Programming is not just code, it‚Äôs a way of thinking and requires problem solving skills that are applicable to other scenarios. You can apply these skills to a range of problems or examples beyond what we will cover in this module. We will be using R which is classified as a high-level programming language - it‚Äôs not the same thing as learning how to use Excel.\nLearning programming is like learning a language - there is grammar and syntax and it takes time and effort to learn and to practice. Don‚Äôt expect to pick it up like memorising content from a lecture - take it in small steps.\nBasic computing terms\rWe don‚Äôt always formally learn computing terminology even if we‚Äôve always been using computers. Here are some general computing concepts we will be using and that we expect you to be familiar with:\nDrives, Folders \u0026amp; Files\rIn computer science, most commercial operating software are organised in to drives, directories, folders \u0026amp; files. Using Windows as example:\rC:/ is a drive (a hard drive). Within the drive, information is sorted in folders (e.g.¬†Documents). Within folders are groups of files which contain information (e.g.¬†my_document.doc). Here, ‚Äú.doc‚Äù is the file extension that tells the computer what kind of file it is and what program to use to read the information (a Word document). Folders within folders are sometimes called sub-folders.\nCommercial computers tend to have only one drive but you can have as many folders and files as you want. For example:\nC: (the hard drive)\r-\u0026gt; my documents (within drive C)\r-\u0026gt; file A (within my documents)\r-\u0026gt; folder 1 (within my documents)\r-\u0026gt; folder 2 (within folder 1)\r-\u0026gt; file B (within folder 2)\r\rDirectories\rDirectories are the cataloguing system describing where files and folders are stored; also called addresses. Directories take the form of an address like ‚ÄúC:/documents/folder/file‚Äù which tells a program to look in this location. The concept of folders and files comes from the days before computers where information was written on paper and stored in filing cabinets. Directories are not case sensitive.\n\rWe recommend that you organise your files in a structured way. For example, have a folder for the module and sub-folders for each of the practicals:\nDocuments (folder) -\u0026gt; Biostats (folder) -\u0026gt; Practical 1 (folder) -\u0026gt; Script (file)\nWe don‚Äôt recommend using a automatically selected ‚Äúdownloads‚Äù folder or your ‚Äúdesktop‚Äù because these are not permanent file locations and can be hard to find files later.\n\rNotice that the components of the address is separated using a forward slash /. R can understand / but does not understand back slash \\ because back slashes have a specific meaning in programming. When typing addresses, make sure you use the correct slash.\nWe navigate through our computer‚Äôs directories using Explorer in Windows or Finder in MacOS. You can see the address of a directory in the address bar. We will learn how to use directories in RStudio.\n\r\rWhy R?\rR is just one of many high-level programming languages used professionally (e.g.¬†C++, Java, Python) but R is specially designed for doing statistics and data handling. Hence R is widely taught in statistic classes. There are other statistics programs but these are normally ‚Äúpoint-and-click‚Äù programs where you click a button and magic happens. The reasons we use R are that it is an open source software and it is transparent, meaning you can see how your data is being manipulated. Transparency allows us to check whether the statistics is done correctly and is easier to see how statistical theory is being applied. R is also reproducible because R allows you to document your code in scripts that you can give another person to replicate your analysis. The traditional option is to learn these calculations by hand and use pre-calculated statistical reference tables but we would only expect that for very simple examples and doing calculations by hand is an arduous task for realistic biological problems.\n\rWhy RStudio?\rR and RStudio are different software. R is a computer programming language and statistical environment. RStudio is a user interface which has some useful features that makes using R easier. It is possible to use R by itself (you can try it) but RStudio makes everything a lot easier by providing some organisation. You cannot use RStudio without R. An analogy is that R is the engine of a car and RStudio is the steering wheel - you control the wheel but the engine is what makes the car go forward.\n\r\rInstalling R and RStudio\rYou will need to install R AND RStudio in that order. You only need to open RStudio when you want to use R - RStudio will open R for you in the background.\n\rHere‚Äôs a video about installing R https://vimeo.com/203516510 and RStudio https://vimeo.com/203516968\n\rYou can follow the instructions below or try the interactive tutorial at https://learnr-examples.shinyapps.io/ex-setup-r/#section-welcome\nHere are the instructions for various operating software:\nWindows\rFor R:\nGo to https://cran.r-project.org/bin/windows/base/\rClick ‚ÄúDownload R‚Äù in the blue box. The version number is not important.\rSave the file, open it and follow the instructions. You can leave everything as the default option. Make sure you‚Äôve installed the program somewhere sensible like the Programs folder in the C:/ drive.\rOpen it and check it installed properly\r\rFor RStudio:\nGo to https://rstudio.com/products/rstudio/download/\rClick download for RStudio Desktop Open Source Licence. The FREE option.\rInstall the program somewhere sensible\rOpen it and check it installed properly\r\r\rMac\rFor R:\nGo to https://cran.r-project.org/\rClick ‚ÄúDownload R for (Mac) OS X‚Äù\rSave the latest release file (e.g.¬†R-4.0.2.pkg), open it and follow the instructions. You can leave everything as the default option. Make sure you‚Äôve installed the program somewhere sensible.\rOpen it and check it installed properly\r\rFor RStudio:\nGo to https://rstudio.com/products/rstudio/download/\rClick download for RStudio Desktop Open Source Licence. The FREE option.\rInstall the program somewhere sensible\rOpen it and check it installed properly\r\r\rLinux\rFor R:\nGo to https://cran.r-project.org/\rClick ‚ÄúDownload R for Linux‚Äù\rClick your version of Linux\rCopy and paste the relevant installation code\rOpen R and check it installed properly\r\rFor RStudio:\nGo to https://rstudio.com/products/rstudio/download/\rClick download for RStudio Desktop Open Source Licence. The FREE option.\rRun the relevant code\rOpen it and check it installed properly\r\rSee https://linuxconfig.org/rstudio-on-ubuntu-18-04-bionic-beaver-linux for a guide\n\rChromebook\rThere are a few options:\n\rThe easiest option is to run Linux on your computer, then you can install R and RStudio. Try the instructions on https://blog.sellorm.com/2018/12/20/installing-r-and-rstudio-on-a-chromebook/ or https://github.com/jennybc/operation-chromebook#links-re-r-and-rstudio\rUse RStudio Server\rUse RStudio Cloud https://rstudio.cloud/ (in beta so it may not work)\r\rSorry chromebook users, if your chromebook version is very old then it may not be possible to install R.\n\r\rOpening R and RStudio for the first time\rIf you open R itself you‚Äôll see that it‚Äôs pretty bare bones. Most annoyingly you have to remember what information is stored in its memory. RStudio is a intermediate program that acts as a mediator between you and R:\nuser -\u0026gt; input -\u0026gt; RStudio -\u0026gt; R -\u0026gt; RStudio -\u0026gt; output -\u0026gt; user\nIf you open RStudio you‚Äôll see several windows that organise how information is passed to R and how output from R is presented:\n\rLeft: The big window is the console. This is the interface with R and is the same as using R on its own. (don‚Äôt worry about ‚Äúterminal‚Äù)\rTop right: This window has three tabs: ‚Äúenvironment‚Äù - shows you what information is stored in R‚Äôs memory, ‚Äúhistory‚Äù - shows your code history \u0026amp; ‚Äúconnections‚Äù - don‚Äôt worry about this one.\rBottom right: This has several tabs. The most important being ‚Äúfiles‚Äù - showing you where RStudio is looking at on your computer \u0026amp; ‚Äúplot‚Äù - shows you any plots you make in R.\r\rYou can customise the layout and colour scheme of RStudio in Options.\nThere are other user interfaces for R but RStudio has a lot of support.\nUpdating R and packages\rThe last major update to R was version 4.0. If you have an older version we recommending updating R because many fundamental aspects of the language were changed and are not backwards compatible. You will see which R version is used in the information in the Console when you open RStudio. If your version is older than 4.0, install the latest version as above.\nR is a statistical environment that consist of packages. Packages are a set of functions that does something to input depending on the underlying code. All your packages are stored in your library. When you download R it comes with a basic set of packages as default which works straight out of the box. This is called base R.\nOnce you‚Äôve installed R you should check all your packages are up to date as well. You can update your packages by clicking the Update button under the Packages tab.\nWe can customise and expand the functionality of R by installing more packages, which are made by people and distributed freely. You can download packages from an online repository using the function install.packages(\"\u0026lt;insert name of package\u0026gt;\"). For example, I wrote this document in RStudio using an additional package called rmarkdown which lets me make HTML, word or PDF files of text, code and figures or tables. We will tell you if you need to install a package but where possible we will be sticking to base R.\n\rCreating a script\rThe greatest advantage of RStudio is that it allows you to write scripts. These are files ending in .R that are created and opened by RStudio. R itself cannot open, read or create scripts. Scripts are text documents of code that you can save on your computer and open later. They provide a guide to what you want to enter to R and saves you from having to type out code over and over again. Before RStudio, we had to save our code in notepad or similar then copy and paste it into R (believe me it was a pain). Now we can do the same but in one click. Importantly, scripts allow reproducibility and helps with problem solving.\nYou can create a new script under File -\u0026gt; New file -\u0026gt; Script (Ctrl+Shift+N) or click the white square with a green and white plus sign in the top left corner.\nSave it and give it an informative name (e.g.¬†‚ÄúDropin1.R‚Äù)\nLet‚Äôs add some code to this script by going through the basics of R! Copy and paste code from below into your script.\n\rRun code from your script rather than directly from the console.\n\rA script is a record of what you‚Äôve done and it makes it easy to spot any mistakes you might have made (transparency \u0026amp; reproducibility). Put your cursor on the line you want to run then press Ctrl+Enter or click Run. You can run multiple lines by highlighting the relevant lines. You can run the entire script from beginning to end using the shortcut Ctrl+Alt+R.\n\rSetting up packages\rTo use a package in R, you need to call it from R‚Äôs library using the function library(). A package we will see later in the module is MASS which contains datasets you can use at home to practice the statistical tests covered in the lectures.\nType library(MASS) into your script then press Enter. You have just run your first line of code. R will load the package MASS in the background. You can check this in RStudio under the Packages tab where there will now be a tick in the box next to MASS.\nRun data() or data(package = .packages(all.available = TRUE)) to see the list of available built-in datasets. Some of these will be relevant to biological sciences, others are more general (e.g.¬†the starwars dataset of Star Wars characters comes with the package tidyverse). Entering the name of a dataset will display the entire dataset. Try calling one of the MASS datasets, like Rabbit. You can see the descriptions of each dataset by calling help(\u0026lt;dataset name\u0026gt;), e.g.¬†help(Rabbit) will tell you it describes the blood pressure of rabbits before and after a drug treatment.\n\rWorking directories\rRemember directories? Typing out whole addresses starting from the hard drive is annoying. There is a short cut if we use working directories. Working directories are default directories that programs will look in first. We can then use directory address that are relative to this default address which shortens addresses.\nFor example, following this directory structure:\nC:\r-\u0026gt; documents\r-\u0026gt; file A -\u0026gt; folder 1 -\u0026gt; folder 2 -\u0026gt; file B\rIf the default directory is C:/, then the address for file B is C:/documents/folder1/folder2/fileB.\nBut if we set folder 1 as the working directory C:/documents/folder1/, then we can use the relative address for the file: folder2/fileB. This way we don‚Äôt have to type C:/documents/folder1/ every time.\nNavigating through directories using addresses can be confusing. Another useful command is .. which tells the address to go up a directory. For example, if folder 2 was the working directory C:/documents/folder1/folder2 and we wanted to access file A, then we need to tell the computer to go up two directories. The relative address for the file is: ../../fileA which means that the computer is now looking in the documents folder. In contrast, the relative address for file B is even shorter, fileB, since folder 2 is already the working directory.\nRStudio has a default working directory.\nYou can see which working directory is the default directory in RStudio on the ‚ÄúFiles‚Äù tab. You can also check what working directory R is using by typing getwd() (GET Working Directory). When you run code directly from the Console, it will use the RStudio working directory. The working directory of a script by default is the directory the script is saved in - this may be different to the default working directory in the Files tab. This may be one reason RStudio cannot find a file even with a ‚Äúcorrect‚Äù relative address.\n\rChanging working directories\rYou can change the default RStudio directory under Tools -\u0026gt; Global Options but on a daily basis, changing the directory temporarily under Session -\u0026gt; Set working directory is more useful.\n\rYou will need to know how to change working directories and tell R where to find files through relative addresses because that is how we import and export data to and from R.\n\rThe R function to do the same thing is setwd() (SET Working Directory). e.g.¬†setwd(\u0026lt;insert directory address here\u0026gt;). It is good practice to keep similar files in the same folder. Otherwise you will need to specify the full address when you call a file that exists in another folder and it can get confusing if your files are all over the place.\n\rThink of directories and addresses like postal addresses - if your address is incorrect the postman (R) wouldn‚Äôt know where to go to pick up your parcel (file). If R cannot find a file, check the address or the working directory is correct\n\r\r\rLoading data\rTo use data stored in other files, the data must be loaded or read into R. Imported data must be assigned a name (using \u0026lt;-) or it won‚Äôt be saved to R‚Äôs memory. The read functions are a set of base R function that import data based on how data is saved in the file. In this module we will focus on two types of storing data: tab delimated \u0026amp; comma separated values.\nIn tab deliminated data, values are separated by tabs. e.g.¬†1 2 3 4 5 6 (separated by 1 space). The read function is read.delim() for deliminated.\rIn comma separated values data (CSV), values are separated by commas. e.g.¬†1,2,3,4,5. The read function is read.csv() for CSV.\r\rFiles names or directories are designated as character strings (\"\"). read.table() also works for tables. See help(\"read.table\") for the general inputs.\nThe read functions have two important settings to be aware of:\n\rheader: Use header = FALSE (default) if your data doesn‚Äôt have headers, header = TRUE to force R to recognise headers - usually the first row of data.\rsep: Tells R to recognise how individual observations are separated (hence sep). sep = \"\" or sep = \" \" if it‚Äôs tab separated data (with white spaces between data - \"\" is a general indicator for any whitespace, \" \" is specifically 1 space) or sep = \",\" for comma separated values. If the data didn‚Äôt import properly it could be because the wrong read function or the wrong separator was used - try another one. Most of the time the default will be fine, which means you do not have to manually specify these settings.\r\r\rAlways check that your data loaded properly. We expect you to be able to load data from file or from clipboard during practicals and assessment.\n\rSometimes strings are loaded as factors instead of characters or vice versa. Sometimes the columns are not recognised because the separator character is incorrect. There are always simple solutions to these problems (e.g.¬†a small typo) and you should be able to fix them.\nNow let‚Äôs practice two ways of importing data using read functions: from a file and from the clipboard. The relevant files are available on Blackboard.\n.txt\rText files (.txt) tend to be delimited, meaning information is separated by a space of fixed width. This is loaded using read.delim(). Try loading the file ‚Äúsmall_sleep.txt‚Äù to an R element called small_sleep:\nsmall_sleep \u0026lt;- read.delim(\u0026quot;small_sleep.txt\u0026quot;)\rsmall_sleep\rSpecies BodyWt TotalSleep\r1 Africanelephant 6654.000 3.3\r2 Africangiantpouchedrat 1.000 8.3\r3 ArcticFox 3.385 12.5\r4 Arcticgroundsquirrel 0.920 16.5\r5 Asianelephant 2547.000 3.9\r6 Baboon 10.550 9.8\r7 Bigbrownbat 0.023 19.7\r8 Braziliantapir 160.000 6.2\r9 Cat 3.300 14.5\r10 Chimpanzee 52.160 9.7\r\r.csv\rIf data is separated by a comma, it‚Äôs called a comma separated value file (.csv). Note that .txt files can also be comma separated. The function to read csv is read.csv(). Try loading the file ‚Äúmammal_sleep.csv‚Äù to an R element called mammal_sleep:\nmammal_sleep \u0026lt;- read.csv(\u0026quot;mammal_sleep.csv\u0026quot;)\rData collected in Excel can be saved as a .csv file using the Save As option. CSV is preferred in many instances over the default Excel file type because it is less prone to error. This is what we will mostly be using.\n\rCopying data\rThe Clipboard is where your computer saves information that you‚Äôve copied using ctrl/cmd + c.\nFor quick and dirty data entry, or for copying code from the Internet, you can load data from the clipboard after highlighting data and copying it. You cannot paste data directly into R. But it is always better to save a data file as a .csv file and importing into R so you always have a copy of the raw data you used.\nFor PC:\nmyclip_data \u0026lt;- read.csv(\u0026quot;clipboard\u0026quot;) # also works with read.delim\rFor Mac:\nmyclip_data \u0026lt;- read.csv(pipe(\u0026quot;pbpaste\u0026quot;)) # also works with read.delim\rWeb browsers might display tabbed whitespace differently so try a different separator depending on what web browser you are using (see above). If all else fails, copy the data into Excel and save the file (problem solving!).\nTry it yourself\rFor whichever operating system you have, highlight and copy this data and load this data into R using you new R script. Make sure you are using the correct read function:\n Species BodyWt\r1 Africanelephant 6654.000\r2 Africangiantpouchedrat 1.000\r3 ArcticFox 3.385\r4 Arcticgroundsquirrel 0.920\r5 Asianelephant 2547.000\r6 Baboon 10.550\r7 Bigbrownbat 0.023\r8 Braziliantapir 160.000\r9 Cat 3.300\r10 Chimpanzee 52.160\rSpecies,BodyWt,BrainWt,NonDreaming,Dreaming,TotalSleep,LifeSpan,Gestation,Predation,Exposure,Danger\rAfricanelephant,6654,5712,NA,NA,3.3,38.6,645,3,5,3\rAfricangiantpouchedrat,1,6.6,6.3,2,8.3,4.5,42,3,1,3\rArcticFox,3.385,44.5,NA,NA,12.5,14,60,1,1,1\rArcticgroundsquirrel,0.92,5.7,NA,NA,16.5,NA,25,5,2,3\rAsianelephant,2547,4603,2.1,1.8,3.9,69,624,3,5,4\rBaboon,10.55,179.5,9.1,0.7,9.8,27,180,4,4,4\rBigbrownbat,0.023,0.3,15.8,3.9,19.7,19,35,1,1,1\rBraziliantapir,160,169,5.2,1,6.2,30.4,392,4,5,4\rCat,3.3,25.6,10.9,3.6,14.5,28,63,1,2,1\n\r\r\rChecking the data\r\rAlways check that your data loaded properly. Sometimes strings are loaded as factors instead of characters or vice versa. Sometimes the columns are not recognised because the separator character is incorrect. There are always simple solutions to these problems (e.g.¬†a small typo) and you should be able to fix them.\n\rFor bigger datasets it is easier to view a subset of the data or to use the View() function:\nhead(mammal_sleep, n = 6) # View the first 6 rows (6 is default, can be changed)\rSpecies BodyWt BrainWt NonDreaming Dreaming TotalSleep\r1 Africanelephant 6654.000 5712.0 NA NA 3.3\r2 Africangiantpouchedrat 1.000 6.6 6.3 2.0 8.3\r3 ArcticFox 3.385 44.5 NA NA 12.5\r4 Arcticgroundsquirrel 0.920 5.7 NA NA 16.5\r5 Asianelephant 2547.000 4603.0 2.1 1.8 3.9\r6 Baboon 10.550 179.5 9.1 0.7 9.8\rLifeSpan Gestation Predation Exposure Danger\r1 38.6 645 3 5 3\r2 4.5 42 3 1 3\r3 14.0 60 1 1 1\r4 NA 25 5 2 3\r5 69.0 624 3 5 4\r6 27.0 180 4 4 4\rView(mammal_sleep)\rData structure\rstr() is a handy function for checking the structure of your dataset. Let‚Äôs check the mammal sleep dataset.\nstr(mammal_sleep)\r\u0026#39;data.frame\u0026#39;: 62 obs. of 11 variables:\r$ Species : chr \u0026quot;Africanelephant\u0026quot; \u0026quot;Africangiantpouchedrat\u0026quot; \u0026quot;ArcticFox\u0026quot; \u0026quot;Arcticgroundsquirrel\u0026quot; ...\r$ BodyWt : num 6654 1 3.38 0.92 2547 ...\r$ BrainWt : num 5712 6.6 44.5 5.7 4603 ...\r$ NonDreaming: num NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\r$ Dreaming : num NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\r$ TotalSleep : num 3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\r$ LifeSpan : num 38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\r$ Gestation : num 645 42 60 25 624 180 35 392 63 230 ...\r$ Predation : int 3 3 1 5 3 4 1 4 1 1 ...\r$ Exposure : int 5 1 1 2 5 4 1 5 2 1 ...\r$ Danger : int 3 3 1 3 4 4 1 4 1 1 ...\r\rThe first line tells us that mammal_sleep is a data frame. Which is how R stores observations in rows and columns. Other types are lists and matrices. It also tells us there are 62 observations - meaning the number of rows of data - and 11 variables - meaning the number of columns\rIn the first column of str(), are the names of the columns of the dataset listed with an $ are . So the first column is called Species\rThe second column shows what type of variable the data are: character (chr) for letters, numeric (num) for continuous numbers and integer (int) for discrete numbers. Another type you will encounter are Factors and levels - these are categorical variables.\rThe third column shows the first couple of observations in each column\r\r\rSummarising data\rsummary() shows some summary statistics for the specific variable\nsummary(mammal_sleep) # for all columns\rSpecies BodyWt BrainWt NonDreaming Length:62 Min. : 0.005 Min. : 0.14 Min. : 2.100 Class :character 1st Qu.: 0.600 1st Qu.: 4.25 1st Qu.: 6.250 Mode :character Median : 3.342 Median : 17.25 Median : 8.350 Mean : 198.790 Mean : 283.13 Mean : 8.673 3rd Qu.: 48.202 3rd Qu.: 166.00 3rd Qu.:11.000 Max. :6654.000 Max. :5712.00 Max. :17.900 NA\u0026#39;s :14 Dreaming TotalSleep LifeSpan Gestation Min. :0.000 Min. : 2.60 Min. : 2.000 Min. : 12.00 1st Qu.:0.900 1st Qu.: 8.05 1st Qu.: 6.625 1st Qu.: 35.75 Median :1.800 Median :10.45 Median : 15.100 Median : 79.00 Mean :1.972 Mean :10.53 Mean : 19.878 Mean :142.35 3rd Qu.:2.550 3rd Qu.:13.20 3rd Qu.: 27.750 3rd Qu.:207.50 Max. :6.600 Max. :19.90 Max. :100.000 Max. :645.00 NA\u0026#39;s :12 NA\u0026#39;s :4 NA\u0026#39;s :4 NA\u0026#39;s :4 Predation Exposure Danger Min. :1.000 Min. :1.000 Min. :1.000 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:1.000 Median :3.000 Median :2.000 Median :2.000 Mean :2.871 Mean :2.419 Mean :2.613 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:4.000 Max. :5.000 Max. :5.000 Max. :5.000 summary(mammal_sleep$BodyWt) # summary statistics for body weight\rMin. 1st Qu. Median Mean 3rd Qu. Max. 0.005 0.600 3.342 198.790 48.202 6654.000 \r\r\rTips\r\rCoding is like learning a language. There is grammar, syntax and terminology to learn.\rThe secret to being a coding whiz is practice, practice, practice. Try using R at every opportunity. If you don‚Äôt use it, you lose it.\rIt‚Äôs OK to google everything. No matter how many years you‚Äôve been using R you will forget something basic.\rA lot of programming is logic. If you can‚Äôt describe what you want to achieve in words, then you can‚Äôt code it. Sometimes the solution means changing your way of thinking about a problem.\rA lot of errors come from spelling or syntax mistakes. It doesn‚Äôt mean you don‚Äôt know it, check your code carefully for typos. Missing brackets or quotation marks are common mistakes.\rOften, copying and pasting your error message into google comes up with the solution\rTrial and error is a big part of programming. If it doesn‚Äôt work the first time, tweak it and try it again. Getting a function to work might be as simple as adding or removing one of the defined parameters.\r\r\rFinding help\rAll R code comes with help files. You can access them from the ‚ÄúHelp‚Äù tab in RStudio. If you want help on a specific function, then you can type in help(\u0026lt;insert function name here\u0026gt;). If you don‚Äôt know your exact query, you can search using ??\u0026lt;insert term here\u0026gt; - e.g.¬†??mean.\nThe Internet is really really great for R help. Websites like StackExchange are help forums for programming. Most likely your question has already been answered on StackExchange. The trick is knowing what to type into Google.\nLearning to problem solve independently is not something you learn by reading or something you can be taught. It is a skill you have to learn by doing, which means having a go yourself before seeking help from others. Make asking for help your last option. You‚Äôll see on StackExchange people describe what they want to achieve, what they have done so far, identified what the problem is and provide some reproducible code to help someone else understand their problem. It‚Äôs really hard to fix someone‚Äôs coding problem without context.\n\rFinal checklist\r\rHave you installed R?\rHave you installed RStudio?\rAre all your versions and packages up to date?\rDo you know how to create and save an R script?\rDo you know how to set your working directory?\rCan you import data into R?\rCan you run a line of code?\rCan you use a function?\r\r\r","date":1630108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630108800,"objectID":"726db3bf28a75be1a7b405a79c489e25","permalink":"https://jacintak.github.io/teaching/introR/","publishdate":"2021-08-28T00:00:00Z","relpermalink":"/teaching/introR/","section":"teaching","summary":"Download and set up R and RStudio","tags":["teaching","R stats","code"],"title":"Setup R","type":"teaching"},{"authors":[],"categories":["code"],"content":"\r\rPhylopic is an online database of silhouettes of species. Most are freely available, with various copyright licences. It‚Äôs a great resource for scientific illustration or making cool presentations.\nOne way I wanted to use Phylopic was to add a silhouette of an animal directly to an R figure. You could search Phylopic yourself and copy the image id to add the icon to the graph but where‚Äôs the fun in that?\nrphylopic is an R package that can search and retrieve icons directly from Phylopic. You can use rphylopic with ggplot2 or base graphics.\nThe process of searching Phylopic and pulling out the image id is not straightforward, and I didn‚Äôt find a step-by-step guide I liked for doing so, so here is a reproducible example using the built in dataset beaver1 - a time series of a beaver‚Äôs body temperature.\nThe data looks like this and we want to add a beaver icon to the top left corner:\nbeaver_plot \u0026lt;- qplot(beaver1$temp,x = seq_along(beaver1$temp), geom = \u0026quot;line\u0026quot;, xlab = \u0026quot;Time\u0026quot;, ylab = \u0026quot;Temperature\u0026quot;)\rbeaver_plot\rStep-by-step guide to adding a Phylopic icon\r1. Getting the right species\rYou can search Phylopic by species using name_search. You might get multiple hits because there may be multiple matches in the databases. It‚Äôs worth cross-referencing the NameBank ID with the website. The NameBank ID is located at the top right of the webpage. In this case we want the first option - 109179.\nlibrary(rphylopic)\rbeaver \u0026lt;- name_search(text = \u0026quot;Castor canadensis\u0026quot;, options = \u0026quot;namebankID\u0026quot;)[[1]] # find names\rbeaver\r\r2. Extracting the id of the icon you want\rUse name_images to list all the beaver icons available. In this case, there are two versions of the beaver icon we can use - listed as $same[[1]] and $same[[2]] with unique uid. The uid is the unique id of the icon. Again, it‚Äôs handy to check the uid with the website. You can find the uid on the website by clicking the actual icon you want to use and copying from the address bar.\nbeaver_id_all \u0026lt;- name_images(uuid = beaver$uid[1]) # list images\rbeaver_id_all\rLet‚Äôs use the second icon and extract only that uid.\nbeaver_id \u0026lt;- name_images(uuid = beaver$uid[1])$same[[2]]$uid # get individual image id\rbeaver_id\r\r3. Getting the icon itself\rNow we can get the actual image using image_data. Each icon is available in different sizes, from a thumbnail (64 px) to large icons (1042 px). We will get a 256 px icon so that the resolution is high enough to avoid pixelation.\nbeaver_pic \u0026lt;- image_data(beaver_id, size = 256)[[1]] # get actual icon, define size. Don\u0026#39;t run this alone\r\r4. Adding the beaver icon to the plot\rUse add_phylopic to add the icon to a ggplot2 graph. You need to specify the x and y axis co-ordinates for the graph. Use ysize to change the size of the icon. Use alpha to control the transparency. colour will change the colour.\nbeaver_plot + add_phylopic(beaver_pic, alpha = 1, x = 10, y = 37.4, ysize = 10)\rThe final plot\n\rAnd that‚Äôs it! ü¶´\n\r\rOther uses of rphylopic\r\rYou can add the icon as a background image but I would question why that would be a good idea from a graphic design perspective. To do so, you don‚Äôt need to specify any other variables in add_phylopic.\rYou can also use icons as data points by plotting each icon in place of the regular point within a for loop. You can see an example in the rphylopic documentation.\r\r\r","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"117841f0586f12e7501e3f4591c93eee","permalink":"https://jacintak.github.io/post/2021-08-01-rphylopic/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/post/2021-08-01-rphylopic/","section":"post","summary":"A step-by-step guide to rphylopic","tags":["R stats","ggplot2","code"],"title":"How to add a Phylopic icon to your graph in R","type":"post"},{"authors":["Jacinta Kong","A. A. Hoffmann","M. R. Kearney"],"categories":null,"content":"Insect life cycles are adapted to a seasonal climate by expressing alternative voltinism phenotypes‚Äîthe number of generations in a year. The problem is to understand how this phenotypic variation along latitudinal gradients is generated through the interactions between environmental factors, like temperature, and the traits of organisms, like development rate and dormancy. However, our current understanding is limited by how thermal responses are characterised, competing theories of thermal adaptation and an incomplete understanding of complex life cycles. Using the widely distributed grasshopper genus Warramaba as a model, we aimed to reconcile theories of thermal adaptation and tested their respective predictions. We hypothesised that the egg stage was a critical life stage for generating latitudinal patterns of voltinism in Warramaba. We described patterns of voltinism and thermal response of egg development rate within and among species of Warramaba along a latitudinal temperature gradient. We found a latitudinal pattern of univoltinism at high latitudes and multivoltinism at low latitudes that corresponded with remarkably strong divergence in egg dormancy patterns and thermal responses of egg development. We argue that the switch in voltinism along the latitudinal gradient was generated by the combined predictions of the evolution of voltinism and of thermal adaptation. We conclude that analyses of latitudinal patterns in thermal responses and corresponding life histories need to consider the evolution of thermal response curves within the context of seasonal temperature cycles rather than based solely on optimality and trade-offs in performance.\n","date":1625753100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625753100,"objectID":"5f2733e01568d1babf63e6e6d23a28ae","permalink":"https://jacintak.github.io/talk/SEB2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/SEB2021/","section":"talk","summary":"Thermal adaptation and plasticity of egg development generates latitudinal patterns in insect life cycles under seasonal climates","tags":["PhD","conference","ectotherms","thermal response","life cycles"],"title":"Society for Experimental Biology Annual Meeting","type":"talk"},{"authors":["Jacinta Kong","J.-F. Arnoldi","A. L. Jackson","A. E. Bates","S. A. Morley","J. A. Smith \u0026 N. L. Payne"],"categories":null,"content":"","date":1625655600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625655600,"objectID":"e9c30482f99ff4c0549103725e048bf6","permalink":"https://jacintak.github.io/talk/BESMacro2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/BESMacro2021/","section":"talk","summary":"Ectotherm heat limits track biological rates","tags":["postdoc","conference","ectotherms","temperature"],"title":"BES Macro 2021","type":"talk"},{"authors":null,"categories":["code"],"content":"\r\rThis tutorial was originally presented to NERD club on 4/2/2020.\nCity maps\rConsider yourself a hipster?\nDo the clean lines and natural materials of modern scandi make you feel at home?\nIs your basic coffee order a flat white? ‚òï\nIf the answer to all the above is YES, then here‚Äôs a present for you!\n\r\rBut wait! This poster costs ‚Ç¨30 (thereabouts) online!\rSee example.\nThat‚Äôs approximately 9 flat whites you could have had.\n‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï\nCan you make this in R?, you ask, asking for a friend.\nFear not. You can make this yourself in R!\n\rMaps in R\rIn this tutorial we will replicate a poster like this. We will need R and powerpoint to put in the final touches. You could do it fully in R but powerpoint will make our lives a bit easier. In summary, it requires a bit of GIS wrangling to code in what you want to display.\nThe data is freely available from Openstreetmap, for proprietary haters out there. I will refer to it as OSM.\nWe will be following this tutorial.\nSetup\rYou will need to install the relevant packages: osmdata, tidyverse and sf.\n#install.packages(\u0026quot;osmdata\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;sf\u0026quot;)\rlibrary(osmdata)\rlibrary(tidyverse)\rAs you can see this will use tidyverse and I will be using piping. Don‚Äôt worry if you are not a master at piping. The code is written.\n\rIn a nutshell, instead of function2(function1(X)) to apply function 1 then function 2 to X, you type x %\u0026gt;% function1() %\u0026gt;% function2(). I.E. take X, apply function 1, then apply function 2 to the resulting output. Overall it‚Äôs easier to read, hence it‚Äôs ‚Äòtidy‚Äô.\n\r\rOSM data\rOSM stores various features you can explore under available_features(). You can see what is under each feature with available_tags(\"\u0026lt;insert feature name here\u0026gt;\").\n\r\r1. Get city co-ordinates\rFor this example we will make a map of Dublin. First we need the latitude and longitude of Dublin. If you want to modify the extent of your map, this is where you change the co-ordinates.\ncity_coords \u0026lt;- getbb(\u0026quot;Dublin Ireland\u0026quot;)\r#city_coords \u0026lt;- c(-6.391,53.2644,-6.114883, 53.416) # to get all the M50\r\r2. Get map features\rRoads\rWe can get roads by querying OSM for the GPS co-ordinates for Dublin and saving it to a variable called roads.\nroads \u0026lt;- city_coords %\u0026gt;% #pipe!\ropq() %\u0026gt;% # create query for OSM database\radd_osm_feature(key = \u0026quot;highway\u0026quot;, value = c(\u0026quot;motorway\u0026quot;, \u0026quot;primary\u0026quot;, \u0026quot;secondary\u0026quot;, \u0026quot;tertiary\u0026quot;)) %\u0026gt;%\rosmdata_sf() # save it as an simple features format\rroads\r\rStreets\rWe can do the same for streets.\nstreets \u0026lt;- city_coords%\u0026gt;%\ropq()%\u0026gt;%\radd_osm_feature(key = \u0026quot;highway\u0026quot;, value = c(\u0026quot;residential\u0026quot;, \u0026quot;living_street\u0026quot;,\r\u0026quot;unclassified\u0026quot;,\r\u0026quot;service\u0026quot;, \u0026quot;footway\u0026quot;)) %\u0026gt;%\rosmdata_sf()\r\rWater\rCan‚Äôt forget the Liffey and the canals. Sadly the ocean cannot be mapped.\nwater \u0026lt;- city_coords%\u0026gt;%\ropq()%\u0026gt;%\radd_osm_feature(key = \u0026quot;waterway\u0026quot;, value = c(\u0026quot;canal\u0026quot;, \u0026quot;river\u0026quot;)) %\u0026gt;%\rosmdata_sf()\r\r\r3. Plotting\rTime to call ggplot2 and plot our map.\nmap \u0026lt;- ggplot() +\r# roads\rgeom_sf(data = roads$osm_lines,\rinherit.aes = FALSE,\rcolor = \u0026quot;grey\u0026quot;, # colour of feature\rsize = 0.8, # Size on map\ralpha = 0.8) + # transparency\r# streets\rgeom_sf(data = streets$osm_lines,\rinherit.aes = FALSE,\rcolor = \u0026quot;#ffbe7f\u0026quot;,\rsize = 0.2,\ralpha = 0.6) +\r# water\rgeom_sf(data = water$osm_lines,\rinherit.aes = FALSE,\rcolor = \u0026quot;steelblue\u0026quot;,\rsize = 0.8,\ralpha = 0.5) +\r# extent to display\rcoord_sf(xlim = c(city_coords[1],city_coords[3]),\rylim = c(city_coords[2],city_coords[4]),\rexpand = FALSE) +\r# remove axes\rtheme_void()\rmap\r\r4. Labels\rAt this point it is easier to save the file and add text in powerpoint but if you want to try your hand at ggplot‚Äôs annotation features go ahead.\nHere I‚Äôve done one in a dark colour scheme.\ntheme_colour \u0026lt;- \u0026quot;#282828\u0026quot; # dark theme\rdark_map \u0026lt;- map +\rlabs(caption = \u0026quot;Dublin, Ireland\u0026quot;) +\rtheme(axis.text = element_blank(),\rplot.margin=unit(c(1,1,1,1),\u0026quot;cm\u0026quot;),\rpanel.grid.major = element_line(colour = theme_colour),\rpanel.grid.minor = element_line(colour = theme_colour),\rplot.background = element_rect(fill = theme_colour),\rpanel.background = element_rect(fill = theme_colour),\rplot.caption = element_text(size = 24, colour = \u0026quot;white\u0026quot;, hjust = 0.5, vjust = -2, family = \u0026quot;mono\u0026quot;),\rpanel.border = element_rect(colour = \u0026quot;white\u0026quot;, fill=NA, size=2),\raxis.ticks = element_blank())\rdark_map\rSaving our map\rggsave(plot = dark_map, filename = \u0026quot;NERD/dark_dublin.pdf\u0026quot;, width = 11, height = 8.5, device = \u0026quot;pdf\u0026quot;, dpi = 300)\rIf all of that was too much, there‚Äôs an R package for it. https://github.com/lina2497/Giftmap\nThere is also a website\n\r\rExtra details\rLess is more but if you really want to put more features:\nOther water bodies\rextra_water \u0026lt;- city_coords %\u0026gt;%\ropq()%\u0026gt;%\radd_osm_feature(key = \u0026quot;natural\u0026quot;, value = c(\u0026quot;water\u0026quot;)) %\u0026gt;%\rosmdata_sf()\rdark_map +\rgeom_sf(data = extra_water$osm_polygons,\rinherit.aes = FALSE,\rfill = \u0026quot;steelblue\u0026quot;,\rcolour = NA,\ralpha = 0.5) +\rgeom_sf(data = extra_water$osm_multipolygons,\rinherit.aes = FALSE,\rfill = \u0026quot;steelblue\u0026quot;,\rcolour = NA,\ralpha = 0.5) +\r# extent to display\rcoord_sf(xlim = c(city_coords[1],city_coords[3]),\rylim = c(city_coords[2],city_coords[4]),\rexpand = FALSE)\r\rParks\rNature reserves including Dublin Bay\npark \u0026lt;- city_coords%\u0026gt;%\ropq()%\u0026gt;%\radd_osm_feature(key = \u0026quot;leisure\u0026quot;, value = c(\u0026quot;park\u0026quot;)) %\u0026gt;%\rosmdata_sf()\rdark_map +\rgeom_sf(data = park$osm_polygons,\rinherit.aes = FALSE,\rfill = \u0026quot;darkgreen\u0026quot;,\rcolour = NA,\ralpha = 0.3) +\rgeom_sf(data = park$osm_multipolygons,\rinherit.aes = FALSE,\rfill = \u0026quot;darkgreen\u0026quot;,\rcolour = NA,\ralpha = 0.3) +\r# extent to display\rcoord_sf(xlim = c(city_coords[1],city_coords[3]),\rylim = c(city_coords[2],city_coords[4]),\rexpand = FALSE)\r\r\rEnd\rThat‚Äôs the gist of using OSM in R. You can use the same code to make any map, e.g.¬†for a paper.\n\r","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"c1e6daebce585feaf9f52534df125c22","permalink":"https://jacintak.github.io/post/2021-07-01-OSM-in-R/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/post/2021-07-01-OSM-in-R/","section":"post","summary":"Make a map in R using Open Street Map","tags":["teaching","R stats","code","NERD club"],"title":"OSM in R","type":"post"},{"authors":null,"categories":null,"content":"\r\r\rInstallation\r1. List of palettes\r\rUnderstanding the structure of the palette\r\r2. Defining and using a palette\r3. Visualise a palette\rPalettes\rPalette by categories\r\rBirds\rFish\rFrogs\rInverts\rLandscapes\rLizards\rMammals\rPlants\rSnakes\rWarramaba grasshoppers\r\r\r\rcolRoz is a themed colour palette package by Jacinta Kong \u0026amp; Nicholas Wu.\nThe palettes are based on the colour schemes of Australia.\ncolRoz can:\n\rGenerate a palette of discrete colours of a specified number\rGenerate a gradient continuous colours of a specified number\r\rFor this, there are three functions described below. Before that, let‚Äôs set up this introduction.\nInstallation\rdevtools::install_github(\u0026quot;jacintak/colRoz\u0026quot;)\rcolRoz works with base R and ggplot2 because it is a palette generator and doesn‚Äôt have a built in ggplot palette function.\n\r1. List of palettes\rThe oz_palettes function contains the list of palettes available. Individual palettes are gouped by theme in a list. The oz_palettes variable is a list of these collated lists.\nnames(oz_palettes) # See all palette themes\r[1] \u0026quot;warramaba\u0026quot; \u0026quot;lizards\u0026quot; \u0026quot;landscapes\u0026quot; \u0026quot;birds\u0026quot; \u0026quot;frogs\u0026quot; [6] \u0026quot;snakes\u0026quot; \u0026quot;plants\u0026quot; \u0026quot;fish\u0026quot; \u0026quot;inverts\u0026quot; \u0026quot;mammals\u0026quot; names(oz_palettes$lizards) # See all lizard palettes\r[1] \u0026quot;c.decresii\u0026quot; \u0026quot;c.kingii\u0026quot; \u0026quot;e.leuraensis\u0026quot; \u0026quot;i.lesueurii\u0026quot; [5] \u0026quot;l.boydii\u0026quot; \u0026quot;m.horridus\u0026quot; \u0026quot;m.horridus2\u0026quot; \u0026quot;t.nigrolutea\u0026quot; [9] \u0026quot;v.acanthurus\u0026quot; \u0026quot;v.pilbarensis\u0026quot; \u0026quot;n.levis\u0026quot; \u0026quot;s.spinigerus\u0026quot; [13] \u0026quot;e.kingii\u0026quot; \rWe can call a specific list using subsetting rules for lists.\noz_palettes[[\u0026quot;warramaba\u0026quot;]][[\u0026quot;whitei\u0026quot;]] # Subset the palette for Warramaba whitei, format: [[theme list]][[palette list]]\r[,1] [,2] [,3] [,4] [,5] [,6] [1,] \u0026quot;#E5A430\u0026quot; \u0026quot;#9C7210\u0026quot; \u0026quot;#D7A8B8\u0026quot; \u0026quot;#BAB24F\u0026quot; \u0026quot;#392821\u0026quot; \u0026quot;#9B391B\u0026quot;\r[2,] \u0026quot;1\u0026quot; \u0026quot;3\u0026quot; \u0026quot;6\u0026quot; \u0026quot;5\u0026quot; \u0026quot;4\u0026quot; \u0026quot;2\u0026quot; oz_palettes$warramaba$whitei # does the same as above but using list names\r[,1] [,2] [,3] [,4] [,5] [,6] [1,] \u0026quot;#E5A430\u0026quot; \u0026quot;#9C7210\u0026quot; \u0026quot;#D7A8B8\u0026quot; \u0026quot;#BAB24F\u0026quot; \u0026quot;#392821\u0026quot; \u0026quot;#9B391B\u0026quot;\r[2,] \u0026quot;1\u0026quot; \u0026quot;3\u0026quot; \u0026quot;6\u0026quot; \u0026quot;5\u0026quot; \u0026quot;4\u0026quot; \u0026quot;2\u0026quot; \rUnderstanding the structure of the palette\rLists within lists may seem daunting but you‚Äôd rarely need to access the palettes individually. It is also easy enough to add your own palettes if you are comfortable with manually editing package functions in R.\nWe are happy to accept community contributions. Adding pre-chosen hex codes is easy to do. It may take longer to make a palette if we need to chose hex colours from an image.\nThe general structure for a set of palettes is:\npalette \u0026lt;- list(\rpal1 = rbind(c(\u0026lt;hex codes\u0026gt;), c(\u0026lt;order of discrete colours\u0026gt;))\r)\rTwo things to note:\n\rThe hex codes are stored as a vector in the first row of the list\rThe second row of the list is a vector of the order colours are used when plotting discrete colours\r\r\r\r2. Defining and using a palette\rThe palettes in this package are set as above. The main function is the palette generator. It acts as a housekeeping function to allow R to interpret the desired palette for plotting. The behaviour of this function depends on whether a discrete or continuous palette is desired and the number of colours requested.\nIf a discrete palette of 3 colours is desired, then the function will chose the subset of 3 colours to be included from the full option of colours in a palette. The chosen order of these colours is hard coded in the list of palette.\n\rNote there is no need to tell colRoz what theme the palette you want is in. Type in the palette name and colRoz will search the entire oz_palette list\n\rpal \u0026lt;- colRoz_pal(name = \u0026quot;ngadju\u0026quot;, n = 3, type = \u0026quot;discrete\u0026quot;)\r# a palette of only 3 colours\rlibrary(ggplot2)\rggplot(iris, aes(Petal.Width, Petal.Length , colour=Species)) +\rgeom_point() +\rscale_colour_manual(values = pal) +\rtheme_classic()\rIf a continuous palette is desired, then the function will use the function colorRampPalette in the grDevices package (included in R) to generate a gradient of colours between the first and last colour in the desired palette.\n\"continuous\" palettes are generated by default if the type argument is left blank. In ggplot2, use the function scale_colour_gradientn to set the continuous scale.\npal \u0026lt;- colRoz_pal(name = \u0026quot;ngadju\u0026quot;, n = 50, type = \u0026quot;continuous\u0026quot;)\rggplot(iris, aes(Petal.Width, Sepal.Length , colour=Petal.Length)) +\rgeom_point() +\rscale_colour_gradientn(colours = pal) +\rtheme_classic()\r***\n\r3. Visualise a palette\rThe function to plot the palette is only for graphing. Information is taken about the number of colours to plot from the desired palette and the palette is plotted. The name of the palette is shown.\nprint_palette(colRoz_pal(\u0026quot;c.decresii\u0026quot;))# if empty, all colours are shown\rprint_palette(colRoz_pal(\u0026quot;c.decresii\u0026quot;, type = \u0026quot;discrete\u0026quot;, n = 4))\rprint_palette(colRoz_pal(\u0026quot;c.decresii\u0026quot;, type = \u0026quot;continuous\u0026quot;, n = 30))\r\rPalettes\rcolRoz has a number of palettes sorted by categories:\n\rBirds\rFish\rFrogs\rInverts\rLandscapes\rLizards\rMammals\rPlants\rSnakes\rWarramaba grasshoppers\r\r\rPalette by categories\rBirds\rnames(oz_palettes$birds)\r[1] \u0026quot;p.cincta\u0026quot; \u0026quot;c.azureus\u0026quot; \u0026quot;m.cyaneus\u0026quot; \u0026quot;d.novae\u0026quot; \rBlack-throated finch. Australia‚Äôs 2019 Bird of the Year!\nAzure kingfisher photo by Brenton von Takach\nSuperb fairywren photo by Jessica McLachlan\nEmu\n\rFish\rnames(oz_palettes$fish)\r[1] \u0026quot;r.aculeatus\u0026quot;\rPicasso triggerfish photo by Brenton von Takach. Also called humuhumunukunukuapuaa in Hawaiian (see also the Octonauts episode)\n\rFrogs\rnames(oz_palettes$frogs)\rNULL\rThere are no frog palettes yet! Send us some and have your name here.\n\rInverts\rnames(oz_palettes$inverts)\r[1] \u0026quot;p.mitchelli\u0026quot; \u0026quot;k.tristis\u0026quot; \u0026quot;m.oscellata\u0026quot; \u0026quot;a.conica\u0026quot; [5] \u0026quot;v.viatica\u0026quot; \u0026quot;c.brevi\u0026quot; \u0026quot;a.westwoodi\u0026quot; \u0026quot;a.plagiata\u0026quot; [9] \u0026quot;physalia\u0026quot; \u0026quot;c.australasiae\u0026quot; \u0026quot;k.scurra\u0026quot; \u0026quot;l.vestiens\u0026quot; [13] \u0026quot;t.australis\u0026quot; \rMitchell‚Äôs diurnal cockroach photo by Craig White\nChameleon grasshopper photo by Kate Umbers\nGaudy acacia grasshopper\nGiant green slant-face\nMatchstick grasshopper, VIC. See Vandiemenella grasshoppers\nShort-tailed nudibranch, Port Philip Bay, VIC\nTortoise beetle\nTwo-spots tiger moth\nBluebottle. Undescribed species\nGreen grocer cicada\nKey‚Äôs matchstick grasshopper. See more info about K. scurra\nSea cucumber, intertidal VIC\nBiscuit star, Port Phillip Bay, VIC\n\rLandscapes\rnames(oz_palettes$landscapes)\r[1] \u0026quot;uluru\u0026quot; \u0026quot;shark_bay\u0026quot; \u0026quot;sky\u0026quot; \u0026quot;desert_sunset\u0026quot;\r[5] \u0026quot;desert_dusk\u0026quot; \u0026quot;desert_flood\u0026quot; \u0026quot;salt_lake\u0026quot; \u0026quot;daintree\u0026quot; [9] \u0026quot;spinifex\u0026quot; \u0026quot;nq_stream\u0026quot; \u0026quot;kimberley\u0026quot; \u0026quot;capricorn\u0026quot; \rPhoto from Jordan Iles\n\rLizards\rnames(oz_palettes$lizards)\r[1] \u0026quot;c.decresii\u0026quot; \u0026quot;c.kingii\u0026quot; \u0026quot;e.leuraensis\u0026quot; \u0026quot;i.lesueurii\u0026quot; [5] \u0026quot;l.boydii\u0026quot; \u0026quot;m.horridus\u0026quot; \u0026quot;m.horridus2\u0026quot; \u0026quot;t.nigrolutea\u0026quot; [9] \u0026quot;v.acanthurus\u0026quot; \u0026quot;v.pilbarensis\u0026quot; \u0026quot;n.levis\u0026quot; \u0026quot;s.spinigerus\u0026quot; [13] \u0026quot;e.kingii\u0026quot; \rTawny dragon\nBlue Mountains water skink\nThorny devil\nBlotched blue-tongued skink\nSouth-western spiny tailed gecko\nKing‚Äôs skink\nThree-lined knobtail gecko\nFrilled-neck lizard\nEastern water dragon\nBoyd‚Äôs forest dragon\nSpiny-tailed monitor\nPilbara rock monitor\n\rMammals\rnames(oz_palettes$mammals)\r[1] \u0026quot;p.breviceps\u0026quot; \u0026quot;thylacine\u0026quot; \rSugar glider\nThylacine (T. cynocephalus)\n\rPlants\rnames(oz_palettes$plants)\r[1] \u0026quot;n.violacea\u0026quot; \u0026quot;xantho\u0026quot; \rBlue lily photo by Emma Dalziell\nXanthorrhoea grasstree photo by Sarah Mulhall\n\rSnakes\rnames(oz_palettes$snakes)\r[1] \u0026quot;a.ramsayi\u0026quot;\rWoma python\n\rWarramaba grasshoppers\rThese are palettes based on the colours of matchstick grasshoppers in the genus Warramaba.\rYou can read more about matchstick grasshoppers on Jacinta‚Äôs website.\nThere are other matchstick grasshopper palettes in the inverts palette.\nnames(oz_palettes$warramaba)\r[1] \u0026quot;grandis\u0026quot; \u0026quot;flavolineata\u0026quot; \u0026quot;whitei\u0026quot; \u0026quot;picta\u0026quot; \u0026quot;virgo\u0026quot; [6] \u0026quot;ngadju\u0026quot; \r\r\r","date":1624579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624579200,"objectID":"915eb24acd339dfbfc5b9325f0743bea","permalink":"https://jacintak.github.io/project/colRoz/","publishdate":"2021-06-25T00:00:00Z","relpermalink":"/project/colRoz/","section":"project","summary":"Installation\r1. List of palettes\r\rUnderstanding the structure of the palette\r\r2. Defining and using a palette\r3. Visualise a palette\rPalettes\rPalette by categories\r\rBirds\rFish\rFrogs\rInverts\rLandscapes\rLizards\rMammals\rPlants\rSnakes\rWarramaba grasshoppers\r\r\r\rcolRoz is a themed colour palette package by Jacinta Kong \u0026amp; Nicholas Wu.\nThe palettes are based on the colour schemes of Australia.\ncolRoz can:","tags":["side-project"],"title":"colRoz - A colour package for the land down under","type":"project"},{"authors":null,"categories":null,"content":"\r\rNERD club is a student-led peer-learning and discussion group for staff and postgraduate students in the Departments of Zoology and Botany at Trinity College Dublin. The group meets weekly for topical discussions about science or academia. There are also sub-groups that are dedicated towards specific topics such as R coding and spatial analysis. These sub-groups are focused towards peer-learning where, postgraduates in particular, are encouraged to share their learning experience and expertise in relevant topics.\nI have been an active contributor to NERD club and its sub-groups: R club for R programming and Space Lunch for GIS and spatial analysis. This page documents some of the outputs I have produced for peer-learning activities.\nTutorials\rAdvanced R markdown\rThis is a short presentation showing some of the more advanced features of R Markdown using the R package bookdown including: numbered sections, cross-referencing, bibliographies, CSS and making a website with the static HTML builder.\nPDF: \n\rInteractive functions and loops in R\rThis tutorial describes how to make an R function that asks the user to input values for the function, and how to run a function within a simple for loop.\n\rOSM in R\rThis tutorial describes how to interface with Open Street Maps in R to make a fancy map you can print and give to someone but the same code can be used to make maps for any purpose.\n\rIntroduction to spatial points in R\rThis is a walkthrough of a basic workflow for working with spatial data and rasters in R. Specifically loading a raster, plotting a raster and extracting information from rasters. I use rgbif to get species occurrence records from GBIF and extract temperature data from a raster of global temperatures. A blog post version is here.\nHTML: \n\rFundamental linear regression in R\rThis is a short presentation showing some of the basic features of linear regression in R using lm including: ANOVA tables, summary and residual plots.\nPDF: \n\rModel selection in R\rAn introduction to model parsimony and basic ways of selecting linear models and predictor variables.\nPDF: \n\rFundamental linear regression assumptions\rA run through the fundamental assumptions linear regression in R using lm based on residual plots.\nPDF: \n\r\r","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"7760691d5a073820ba7a7e4ee844da9b","permalink":"https://jacintak.github.io/project/NERD-club/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/project/NERD-club/","section":"project","summary":"My contributions to the Zoology \u0026 Botany NERD Club at Trinity College Dublin","tags":["teaching","R stats","code","NERD club"],"title":"NERD club tutorials","type":"project"},{"authors":null,"categories":["code"],"content":"\r\rThis tutorial was originally presented to NERD club on 18/11/2020.\nThis document contains two examples of functions and an example of how functions can be integrated with loops.\n\rUser defined functions take the general form of function(inputs){processing inputs; return(output)}\n\rPredator-Prey interactions\rWe will use a simulation of predator-prey interactions as an example. Predator-prey interactions simulate how many prey a predator can capture after a specific amount of time and for a given density of prey. We use this example with undergraduate biology students to demonstrate statistical modelling, experimental design and collecting data.\nNormally we would get students to do this laboratory practical in class by picking up counters and putting them in jars while blindfolded. We can also see whether the use of different types of jars affects the efficiency of the predator. This is the experimental design:\n\rResponse variable - Number of prey caught (Ha)\rTotal foraging time - 1 minute, a constant (T)\rPredictor variables:\r\rPrey density - user defined treatments (H)\rType of jar used - jar with a lid or no lid (yes or no)\r\r\rNormally the students will collect data to parameterise the functional response. Instead I‚Äôve created a function that will predict new values of prey captured using a functional response formula that is already parameterised.\nLet‚Äôs look at the function:\nAn interactive function\rR has some capacity to be interactive. It can ask a user to input variables.\rThe function functional_response will return the number of prey captured for a given prey density and type of jar used. The function will ask for these two inputs each time the function is run. Look at the code below and try to understand the different components. Then try running the code yourself with different inputs.\n#### Interactive function\r# Simulation of the predator-prey functional response - DO NOT CHANGE\r# To run: click Source (cmd or ctrl+shift+S) or Run All (ctrl+alt+r)\r# Or source(\u0026quot;\u0026lt;insert file location here\u0026gt;\u0026quot;, echo = FALSE)\rfunctional_response \u0026lt;- function(){\r# Introduce the simulation to the user - prints a message\rcat(paste(\r\u0026quot;\u0026quot;,\r\u0026quot;You have some counters (prey), a piece of A4 paper \u0026amp; a jar.\u0026quot;,\r\u0026quot;You spread the counters randomly on the A4 sheet.\u0026quot;,\rsep=\u0026quot;\\n\u0026quot;))\r# Ask the user for the prey density for the functional response\rprey_density \u0026lt;- readline(\u0026quot;How many prey counters are used? \u0026quot;) # ask for prey density\r# Check the user has inputted a number properly\rif(!grepl(\u0026quot;^[0-9]+$\u0026quot;, prey_density)){ # check whether the input contains numeric characters between 0-9 using regex (regular expressions)\rmessage(\u0026quot;Please enter an integer\u0026quot;) # If the input is not a number, tell them to do it again\rreturn(functional_response()) # Return to the beginning of the function and start again\r}\rprey_density \u0026lt;- as.integer(prey_density) # If the prey density input is a number, turn it into an interger\r# Ask the user for the type of jar used\rcat(paste(\r\u0026quot;\u0026quot;,\r\u0026quot;Every second you (the predator) tap the sheet to find and pick up a prey counter while blindfolded.\u0026quot;,\r\u0026quot;You have 1 minute to put as many prey counters as you can in the jar.\u0026quot;,\r\u0026quot;There are two types of jars you can use while handling prey.\u0026quot;,\r\u0026quot;Enter 1 to use a jar with a lid that you have to open and close.\u0026quot;,\r\u0026quot;Enter 2 to use a jar without a lid.\u0026quot;,\r\u0026quot;\u0026quot;,\r\u0026quot;What type of jar is used?\u0026quot;,\rsep=\u0026quot;\\n\u0026quot;))\rlid_used \u0026lt;- menu(c(\u0026quot;Lid\u0026quot;, \u0026quot;No Lid\u0026quot;))\r# Calculate the number of prey caught (the functional response) based on the user defined input above\rif(lid_used != 0){ # Check that the use has chosen the jar used properly (1 or 2)\r# Use this model if using a jar with a lid\rif(lid_used == 1){\rHa \u0026lt;- (0.2 * prey_density)/(1 + 0.2 * 0.03 * prey_density) }\r# Use this model if using a jar without a lid\rif(lid_used == 2){\rHa \u0026lt;- (0.7 * prey_density)/(1 + 0.7 * 0.05 * prey_density) }\r# Add in some variation around the predicted value so that users don\u0026#39;t get the exact parameterised functional response\rHa \u0026lt;- Ha + sample(seq(-3,3), 1) # Make sure there are no negative prey items caught!\rif(Ha \u0026lt; 0){\rHa \u0026lt;- 0 # Make prey caught 0 if less than 0\r}\r# Make sure the number of prey caught doesn\u0026#39;t exceed the number of prey available!\rif(Ha \u0026gt; prey_density){\rHa \u0026lt;- prey_density # If prey caught is greater than the number of prey available, make it the maximum possible\r}\r# Print a message showing the results\rmessage(\u0026quot;The number of prey caught is \u0026quot;, floor(Ha), \u0026quot;. Well done!\u0026quot;) }\r}\r# Actually run the function and tell R that it\u0026#39;s interactive if(interactive()) functional_response()\rNote:\n\rThe function doesn‚Äôt have any inputs in function() because it will ask the user for them each time\rreadline is the function to ask for a single user input\rmenu is the function to ask the user to chose from a number of options\r\rHere the option is press 1 to use a jar with a lid or press 2 to use a jar without a lid\r\rThere are two parameterised functional responses - one for a jar with a lid and one for a jar without a lid\rfloor is a function to round the number of prey caught to the lowest whole number\r\rIn the practical, students will need to run the above function for 10 prey densities, repeated 3 times, for both jar treatments - so 60 times in total. But we don‚Äôt have to do that manually - that is what loops are for!\n\rFunctions and loops\rHere is a non-interactive version of the function above. It doesn‚Äôt have the printed messages asking for user input. This time, the function needs 3 inputs as indicated by function(prey_density, lid_used, total_time): the prey density used, the type of jar used and the total foraging time, respectively.\nRun the code chunk to load the function into the R environment:\n# Functional response function\rfunctional_response \u0026lt;- function(prey_density, lid_used, total_time){\r# Check jar type is inputted correctly\rif (!lid_used %in% c(\u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot;)) {\rstop(\u0026quot;Lid used is not inputted correctly. Use \u0026#39;yes\u0026#39; or \u0026#39;no\u0026#39; in all lowercase\u0026quot;)\r}\rif(lid_used == \u0026quot;yes\u0026quot;){\rHa \u0026lt;- (0.2 * prey_density * total_time)/(1 + 0.2 * 0.03 * prey_density)\r}\rif(lid_used == \u0026quot;no\u0026quot;){\rHa \u0026lt;- (0.7 * prey_density * total_time)/(1 + 0.7 * 0.05 * prey_density)\r}\rHa \u0026lt;- Ha + sample(seq(-3,3), 1)\rif(Ha \u0026lt; 0){\rHa \u0026lt;- 0\r}\rif(Ha \u0026gt; prey_density){\rHa \u0026lt;- prey_density\r}\r# message(\u0026quot;The number of prey caught is \u0026quot;, floor(Ha))\rreturn(floor(Ha))\r}\rThe function will check that the character vector indicating the type of jar to be used is correct because R is case sensitive. The function will return the number of prey caught Ha as indicated by return(Ha). The function return specifically tells R to tell us the output, otherwise R will keep it to itself! Only one output is allowed (unless extra steps are taken).\rThe rest of the function is the same.\nUsing the functional response function in a loop\rNow let‚Äôs use a loop to do our entire experiment in one go! No manual inputs for us. In fact we can do as many treatments or replicates as we want. Let‚Äôs do prey densities between 5 and 100 in increments of 5 and 3 replicates. Since the function inputs are required we can set them up in the environment for the function:\n# Set parameters for the function\rtotal_time \u0026lt;- 1 # total foraging time in minutes\rno_treatments \u0026lt;- seq(from = 5, to = 100, by = 5) # prey density treatments between 5 and 100\rreplications \u0026lt;- 3 # number of replications\r# a numeric vector of prey densities for all treatments, jar types and replications prey_density \u0026lt;- rep(rep(no_treatments, replications),2) # repeated twice for each jar type\r# a character vector of the jar type\rlid_used \u0026lt;- sort(rep(c(\u0026quot;no\u0026quot;, \u0026quot;yes\u0026quot;), length(prey_density)/2)) # \u0026quot;yes\u0026quot; or \u0026quot;no\u0026quot;\rBy setting up the parameters outside the function or loop, we can easily modify the parameters of the function and feed the new values into the loop. This helps us debug and is cleaner and easier to read.\nNow for the actual loop itself. We need to be able to store the output of the looped function.\rLists are the fastest way to do so in R because R is designed for lists and matrices.\n# Create an empty list called prey_caught to populate prey_caught \u0026lt;- list()\rfor(i in seq_along(prey_density)){\r# Run the functional response for the nth observation in the vector prey_density representing all our observations and save it to the list\rprey_caught[[i]] \u0026lt;- functional_response(prey_density = prey_density[i],\rlid_used = lid_used[i],\rtotal_time = total_time)\r# Prepare the list for further analysis\rprey_caught[[i]] \u0026lt;- cbind(prey_caught[[i]], prey_density[i]) # add a column for the prey density used to calculate the number of prey caught for that observation (row)\rprey_caught[[i]] \u0026lt;- cbind(prey_caught[[i]], 1/prey_caught[[i]]) # add a column for the inverse of the number of prey caught - for statiscally parameterising the functional response\rprey_caught[[i]][,3] \u0026lt;- ifelse(prey_caught[[i]][,3] == Inf, 0, prey_caught[[i]][,3]) # Housekeeping - turn undefined values of prey caught (from calculating 1 divided by 0) into 0. If the number of prey caught was 0\r}\r# Turn our list into a data frame\rprey_caught \u0026lt;- data.frame(do.call(\u0026quot;rbind\u0026quot;, prey_caught))\r# Label the columns\rcolnames(prey_caught) \u0026lt;- c(\u0026quot;Ha\u0026quot;, \u0026quot;H\u0026quot;,\u0026quot;Ha.1\u0026quot;, \u0026quot;HT.1\u0026quot;) # \u0026quot;.1 is inversed columns\u0026quot;\r# Add type of lid used to our data frame\rprey_caught$lid_used \u0026lt;- lid_used\r\rHere we are using a for loop with the nth observation denoted i. This can be called anything you want but i is from mathematical notation.\rseq_along is a useful function for telling which observation you are at for a vector - try it out on its own.\rLists can only contain one variable type, unlike a data frame, but that‚Äôs why they are fast and memory efficient for high performance computing\r\rIf we were to add the jar type (a character vector) to the list within the loop, then all our numeric output will be converted to characters (default R behaviour) - not what we want!\r\rdo.call is a handy function for lists. It collapses multidimensional lists into one dimension, here appending them by rows (i.e.¬†adding new observations by rows at the end)\r\r\rVisualising the data\rNow we can plot our results and conduct our linear regression:\nlibrary(tidyverse)\rprey_caught %\u0026gt;% # Absolute values\rggplot(aes(H, Ha, colour = lid_used)) +\rgeom_point() +\rgeom_smooth(method = \u0026quot;lm\u0026quot;, se = FALSE, fullrange=TRUE) +\rlabs(x = expression(paste(\u0026quot;Prey density (H)\u0026quot;)),\ry = expression(paste(\u0026quot;Prey captured (Ha)\u0026quot;)),\rcolour = \u0026quot;Jar used\u0026quot;) +\rtheme_classic()\r# Linear model\rsummary(lm(Ha.1 ~ HT.1 * lid_used, prey_caught))\r\rCall:\rlm(formula = Ha.1 ~ HT.1 * lid_used, data = prey_caught)\rResiduals:\rMin 1Q Median 3Q Max -0.27245 -0.05371 -0.01596 0.00899 0.84476 Coefficients:\rEstimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 0.07136 0.02262 3.155 0.00204 **\rHT.1 1.00548 0.40029 2.512 0.01338 * lid_usedyes 0.09517 0.03198 2.976 0.00356 **\rHT.1:lid_usedyes -1.11833 0.56609 -1.976 0.05058 . ---\rSignif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rResidual standard error: 0.1351 on 116 degrees of freedom\rMultiple R-squared: 0.08913, Adjusted R-squared: 0.06558 F-statistic: 3.784 on 3 and 116 DF, p-value: 0.01242\rThat has saved us from running the code 120 times! Now we can do it in one!\n\r\r\r","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"e2b5110073a51d6f0b084ea324679b78","permalink":"https://jacintak.github.io/post/2021-06-01-r-function-loops/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/post/2021-06-01-r-function-loops/","section":"post","summary":"A tutorial about interactive functions and loops in R","tags":["teaching","R stats","code","NERD club"],"title":"R Club: Functions \u0026 Loops","type":"post"},{"authors":[],"categories":["code"],"content":"\r\rThis post on R bloggers describes a handy function for formatting really small P values in ANOVA tables (more than 3 decimal places) with \\(\u0026lt;0.001\\). I find this easier to read when I need to present a formatted table, e.g.¬†in teaching.\nThe original function doesn‚Äôt cover all ways of creating ANOVA tables in R so I have extended the function to cover more cases. The fixp function below will work for ANOVA tables (x) generated by anova(lm(...)) and summary(aov(lm(...))), as well as the model coefficients table generated by coef(summary(lm(...))).\nA function to format P values\rfixp \u0026lt;- function(x, dig=3){\r# Convert to a data frame\rif(is.data.frame(x) | is.matrix(x)){\rx \u0026lt;- as.data.frame(x)\r} else {\rx \u0026lt;- as.data.frame(x[[1]])\r}\r# Check column order if(substr(names(x)[ncol(x)],1,2) != \u0026quot;Pr\u0026quot;){\rwarning(\u0026quot;The name of the last column didn\u0026#39;t start with Pr. This may indicate that p-values weren\u0026#39;t in the last row, and thus, that this function is inappropriate.\u0026quot;)\r}\r# Round P values to \u0026quot;dig\u0026quot; decimal places, default 3 x[,ncol(x)] \u0026lt;- round(x[,ncol(x)], dig)\r# for(i in 1:nrow(x)){\rif(x[i,ncol(x)] == 0 \u0026amp; !is.na(x[i,ncol(x)])){\rx[i,ncol(x)] \u0026lt;- paste0(\u0026quot;\u0026lt;0.\u0026quot;, paste0(rep(0,dig-1), collapse=\u0026quot;\u0026quot;), \u0026quot;1\u0026quot;)\r}\r}\rx\r}\rThe main modification to the original function is to expand the conversion of x to a data frame to accept lists and matrices. summary(aov(lm(...))) creates an object with class summary.aov which is a list and the coefficients table is a matrix. Although anova(lm(...)) creates a data frame that will work with the function without a fatal error, the function anova has its own way of ‚Äúpretty‚Äù printing [to quote the help file] which is not compatible with the character vector in the P value column and thus will show a P value of 1. So forcing to a data frame is necessary. A minor modification is to ignore the NAs in the Residual row created by the data frame which would otherwise give an error.\nThe three decimal places for P values is coded into the function by default and can be changed by the dig option. For example, dig = 1 will give you \\(\u0026lt;0.1\\). You can then call your ANOVA table and the fixp function through knitr::kable() or your favourite HTML/LaTeX table formatter. e.g.¬†kable(fixp(anova(lm(...))), digits = ...). If you don‚Äôt want to print NAs, it‚Äôs probably better to use the options in your chosen formatting function - e.g.¬†the knitr.kable.NA option in kable.\n\r","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"f339a7c6751f3f89f044087a04fd2da2","permalink":"https://jacintak.github.io/post/2021-05-01-formatting-p-values/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/post/2021-05-01-formatting-p-values/","section":"post","summary":"An R function for formatting really small P values to print ANOVA or regression coefficient tables","tags":["R stats","code"],"title":"Formatting P values","type":"post"},{"authors":null,"categories":[],"content":"\r\rWhere do animals live and why? These are some of the questions that ecologists are interested in. Sure, we can talk about patterns of abundance in an area in terms of abiotic or biotic factors or niche variation. But what if there‚Äôs more to animals than that?\nWhat if a young animal is concerned not just about eating, being eaten and living to reproduce but also with their finances, housing, commute and social mobility? What if a larger or older individual lives where they live not because they can outcompete smaller individuals for limited resources, but because they have accrued greater capital over time and thus have higher purchasing power?\nNone of these questions are answered by current ecological theory. We need an alternative explanation for animal distributions and abundances. Here, I present to you the socio-economic theory of animal abundance. I illustrate this theory using the Australian ghost crab (Ocypode cordimana) as a case study.\nA case study on ghost crabs\rGhost crabs are a common intertidal species in tropical sandy beaches. Forget beach front digs with a sea view. They have literal digs on the beach. What‚Äôs more, Ocypode cordimana is a species of ghost crab that lives on K‚Äôgarri (Fraser Island), Australia, so they have prime access to the largest sand island in the world in the luckiest country in the world.\nOn K‚Äôgarri, O. cordimana burrows are distributed from the low tide mark to the high sand dunes. The size of the burrows are indicative of the size of the home owner. Larger holes and thus larger crabs are found further up the beach from the shore. Higher densities of smaller holes are found closer to the low tide mark and lower densities of larger holes are found further away from the shore.\nA boring ecologist might hypothesise that this size-abundance gradient is explained by intraspecific competition or gradients of vegetation cover. But here is the socio-economic explanation:\nGhost crabs are nocturnal (hence, ghosty; not because they are terrible friends ‚Äì or are they?). At night they head down to the low tide line and forage among the detritus. This is the Central Business District (CBD) where crabs do their biz and partay. Ghost crabs need to commute every day and, like all reasonable beings, they want to avoid the rush hour traffic least they succumb to road rage. And it would not do to be seen participating in such vulgar behaviour in this day and age. Contests are better left to the dishonest fiddler crabs ‚Äì the cheaters. Rather, all crabs openly carry weapons (claws) as a deterrent via mutually assured destruction.\n\r\rA schematic of a ghost crab. Not to scale.\nCrabs could minimise their commute and live close to the CBD. But living here is dangerous. The sand is fine ‚Äì poor digging quality so only small houses can be built. The close proximity to the CBD and the ocean means the area gets inundated at high tide, which makes insurance premiums go through the roof. Housing density is high and competition for space is fierce. No-one enjoys hearing their neighbours through the fine grain sand. The only crabs that can live here are small, young crabs (including grad students) who can only afford to live in these inner city slums and dream of living further away from the gangland crime.\nIn more recent times, the inner city has been undergoing gentrification. Young working professional crabs (Yuppies) and two-crab social groups with double incomes and no kids (DINKs) have been attracted by the convenience of the commute and short distance to local amenities. These crabs are larger than the typical inner city crab, have the income to create quality residences, and think the incoming tide adds character and charm to their property. These crabs enjoy an overpriced flat white with their avo on toast. You‚Äôll often find them scurrying about to their barber appointments for their frothy bubble beards (plaid not included).\n\r\rThe socio-economic theory of ghost crab abundance on K‚Äôgarri\nBeyond the inner city transition zone lies the urban sprawl known as suburbia. Suburbia is where the hopes and dreams of the young go to die and are replaced with a well manicured lawn. Here, the sand is not as wet, infrequently gets inundated, and one could afford to build a large home. The commute to the CBD is a little longer than the inner city but there‚Äôs the best of both worlds as access to the world class foredunes is equidistant away. Perfect for the weekend escape from the mediocrity.\nFinally, at the base of the dunes are the largest houses. The coarse sand and the roots of the foredune vegetation permit the largest burrows worthy of the largest and wealthiest crabs. Their commute is the longest but they don‚Äôt care about that, if they even need to commute at all. Their elevated position on the dune slope gives them the greatest vistas of the population and they live on the urban-rural fringe with easy access to silver-green, xerophytic spaces.\nBeyond the dune crest lies The Sticks as the dune transitions to woodland containing, you guessed it, sticks. Not the kind of place for crabs so few crabs are found there.\nAnd that is the socio-economic theory of animal abundance applied to ghost crabs.\nHappy April Fools. There is no intellectual basis for applying the concentric zone model of cities to explain real ecological patterns. I initially conceptualised this during my undergrad ecology field trip to K‚Äôgarri many years ago. This post is dedicated to Prof.¬†Gimmie Walter, who heard it first ‚Äì Happy retirement!\nThis post was originally published on EcoEvo@TCD on 1st April 2021.\n\r","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"511e7e792e67d878cc129443c4a237ba","permalink":"https://jacintak.github.io/post/2021-04-01-the-socio-economic-theory-of-animal-abundance/","publishdate":"2021-04-01T00:00:00Z","relpermalink":"/post/2021-04-01-the-socio-economic-theory-of-animal-abundance/","section":"post","summary":"What if there's more to animals than what current ecological theory thinks?\n","tags":["fun","ecology","crabs","theory"],"title":"The socio-economic theory of animal abundance","type":"post"},{"authors":[],"categories":["code"],"content":"\r\rIf it ain‚Äôt broke, don‚Äôt fix it?\rSo you‚Äôve spent a lot of time learning and practising R and you‚Äôre pretty comfortable with using functions, if else statements and loops like they teach at introductory programming. What more is there to improve?\nIf the answer is no or you subscribe to the quote above, then turn back now. If yes, continue.\nI think that even if one has the skills to do fundamental programming competently, there‚Äôs always room for improvement or something new to learn. Or you know that there‚Äôs a better, more efficient, way to do it but something is holding you back. For me, it‚Äôs usually the latter.\nIn a milestone of using R I think I have wrapped my head around replacing for loops with the apply family, specifically mapply. The last hurdle in delving into functional programming.\nI‚Äôve used iterative coding quite a bit over the years and I‚Äôve been using for loops to do so. As I‚Äôve gotten more competent with applying basic concepts (like loops and functions), I‚Äôve been moving towards optimising my code with more advanced R methods. I started with using more manual functions and sourcing functions from external scripts but I was still relying on loops to apply those functions iteratively.\nI know loops are inefficient. I‚Äôve waited days for computationally intensive loops on large datasets to finish. I know that apply and co. can be more computationally efficient but in your typical learning something new way, they hadn‚Äôt really clicked for me‚Ä¶until now.\nI‚Äôve been trying to use apply family functions where appropriate for years but I‚Äôve never felt comfortable with using them to use them from the start. So, I default back to loops to save time and frustration.\nI think the slow uptake is because the syntax is different to the logic of loops that are taught, even if apply‚Äôs logic is better from a computing perspective. The syntax and the logic is also inconsistent within the apply family; a known disadvantage over similar functions (like purrr::map).\nBut let‚Äôs focus on a specific case before this becomes a cooking blog: replacing for loops. I‚Äôm going to assume that you are competent with manual functions, for loops and lists, and that you want to improve your code. I‚Äôm going to focus on lists because they are an efficient way of storing lots of similarly structured data in R.\nHere are two ways to replace a for loop.\n\rAn example loop\rLet‚Äôs create an example scenario and data:\n# some data to use\rloop_data \u0026lt;- data.frame(col1 = c(11:15), col2 = c(20:24))\r# define variable to change\ra \u0026lt;- seq(0.2, 1, 0.2)\r\rloop_data is a data frame with two numeric columns (col1 \u0026amp; col2). We technically won‚Äôt use loop_data$col2 but it‚Äôs there to create a 5x2 data frame.\ra is a variable that we need for our function. There are 5 values.\r\rWe want to add each element of a to loop_data$col1 and save that in a new column loop_data$col1a. We will also add a as a column in loop_data just so we can keep track of which value was used to calculate col1a. So the final output should have 25 rows (5 observations in loop_data x 5 values of a) and 4 columns (col1, col2, col1a, a).\nWe will be storing our data in lists in all our scenarios. Note that I create the list to hold the answers (loop_ans) before the function rather than to append newly calculated answers sequentially to the list within the function. I use the same replicate function before all the examples. You could also start with an empty list.\n# data sets stored as a list - must not simplify or it will reduce to a matrix!\rloop_ans \u0026lt;- replicate(length(a), loop_data, simplify = FALSE)\r# A function to add a value a to a data frame x\rloop_function \u0026lt;- function(x, a) {\rx$col1a \u0026lt;- x$col1 + a # add answer to a new column x$a \u0026lt;- a # add a to a new column\rreturn(x) # give us the updated data frame\r}\r# Let\u0026#39;s loop\rfor(i in seq_along(a)){\rloop_ans[[i]] \u0026lt;- loop_function(loop_ans[[i]], a = a[i]) }\r# merge to single data frame\rloop_ans \u0026lt;- do.call(rbind, loop_ans)\r# view the data\rsummary(loop_ans)\r## col1 col2 col1a a ## Min. :11 Min. :20 Min. :11.2 Min. :0.2 ## 1st Qu.:12 1st Qu.:21 1st Qu.:12.4 1st Qu.:0.4 ## Median :13 Median :22 Median :13.6 Median :0.6 ## Mean :13 Mean :22 Mean :13.6 Mean :0.6 ## 3rd Qu.:14 3rd Qu.:23 3rd Qu.:14.8 3rd Qu.:0.8 ## Max. :15 Max. :24 Max. :16.0 Max. :1.0\rThat‚Äôs the loop - should be familiar to you. Merging into a single data frame is optional if you want to keep using lists. Now let‚Äôs look at lapply for a less elegant solution (!).\n\r1. lapply\rlapply takes a list as input, does stuff and gives a list as output. Hence, the l in lapply stands for list. The difference with loops and lapply is that lapply can only take one input - your data frame (or element in list). This means that we need to add the corresponding value of a as a column in each element of lapply - in other words to do part of what loop_function did but outside the loop/lapply. Thus, each data frame in the input list should have three columns: col1, col2 \u0026amp; a.\nIncidentally, we can add the corresponding a value as a column using mapply and cbind.\n# the function only accepts one element: x\rlapply_function \u0026lt;- function(x){\rx$col1a \u0026lt;- x$col1 + x$a\rreturn(x)\r}\r# Prepare the answer list\rlapply_ans \u0026lt;- replicate(length(a), loop_data, simplify = FALSE)\r# add a column using mapply\rlapply_ans \u0026lt;- mapply(FUN = cbind, lapply_ans, \u0026quot;a\u0026quot; = a, SIMPLIFY = FALSE)\r# apply function\rlapply_ans \u0026lt;- lapply(lapply_ans, FUN = lapply_function)\r# merge to single data frame\rlapply_ans \u0026lt;- do.call(rbind, lapply_ans)\r# view the data\rsummary(lapply_ans)\r## col1 col2 a col1a ## Min. :11 Min. :20 Min. :0.2 Min. :11.2 ## 1st Qu.:12 1st Qu.:21 1st Qu.:0.4 1st Qu.:12.4 ## Median :13 Median :22 Median :0.6 Median :13.6 ## Mean :13 Mean :22 Mean :0.6 Mean :13.6 ## 3rd Qu.:14 3rd Qu.:23 3rd Qu.:0.8 3rd Qu.:14.8 ## Max. :15 Max. :24 Max. :1.0 Max. :16.0\rAs you see it‚Äôs not as simple as the loop or mapply and requires mapply anyway ü§∑\nSo we can do better‚Ä¶\n\r2. mapply\rThe m in mapply stands for multiple because it takes multiple arguments and applies them to the data. There are some key differences in the structure of the data and the function compared to lapply:\n\rWe can use the original loop function with two variables!\r\rThe additional variables (a in this example) are written after the function FUN is defined in mapply\r\rWe can also use the original list (loop_data) without further modification!\rWe need to tell mapply not to simplify the output into a matrix by default. Note the use of upper case in SIMPLIFY.\r\r# Prepare the answer list\rmapply_ans \u0026lt;- replicate(length(a), loop_data, simplify = FALSE)\r# mapply function\rmapply_ans \u0026lt;- mapply(mapply_ans, FUN = loop_function, a = a, SIMPLIFY = FALSE)\r# merge to single data frame\rmapply_ans \u0026lt;- do.call(rbind, mapply_ans)\r# view the data\rsummary(mapply_ans)\r## col1 col2 col1a a ## Min. :11 Min. :20 Min. :11.2 Min. :0.2 ## 1st Qu.:12 1st Qu.:21 1st Qu.:12.4 1st Qu.:0.4 ## Median :13 Median :22 Median :13.6 Median :0.6 ## Mean :13 Mean :22 Mean :13.6 Mean :0.6 ## 3rd Qu.:14 3rd Qu.:23 3rd Qu.:14.8 3rd Qu.:0.8 ## Max. :15 Max. :24 Max. :16.0 Max. :1.0\rWhat mapply is doing is using the nth element of a with the corresponding nth element in the list loop_data. So the fifth value of a (1.0) is used in the calculations on the 5th data frame in loop_data.\nWe‚Äôve replace the for loop with a mapply function! üëè\nHere‚Äôs to functional programming. Next up is purrr::map‚Ä¶\n\r","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"448df46b72ab89a781756c38dbaeb701","permalink":"https://jacintak.github.io/post/using-mapply/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/post/using-mapply/","section":"post","summary":"How I learnt to love replacing for loops with apply","tags":["code","R stats"],"title":"Leaving the valley of intermediate competence","type":"post"},{"authors":null,"categories":null,"content":"\r\rR/exams is an R package that generates a reproducible workflow for designing, producing and marking exams.\nHere, I provide a short walkthough for generating an online test for Blackboard - see the R/exams website for some tutorials.\nInstallation\rInstall R/exams via CRAN with install.packages(\"exams\").\n\rRunning the package for the first time\rexams uses rtools to create zip files. Make sure the proper rtools is installed. An error message will appear if rtools does not have permission to create zip files.\nTo give permission for creating .zip for windows:\rControl Panel \u0026gt; System and Security \u0026gt; System \u0026gt; Advanced System Settings \u0026gt; Environmental Variables \u0026gt; add ‚ÄúC:/RTools/bin‚Äù\nYou may also need to install dependent packages like tth for math notation.\n\rTypes of questions\r\rSingle correct answer MCQ (schoice)\rMultiple correct answer MCQ (mchoice)\rNumeric answer (num)\rString (string)\r\rCloze is another option but is not supported by blackboard, this permits a combination of the above for the MCQ answer list\n\rBuilding an exam question\rThere are several file types that are supported when writing your question but I have stuck with ‚Äò.Rmd‚Äô. There are four parts of a question file:\nThe question\rThe answer list\rThe solution list for giving feedback\rThe meta-information\r\rEach of these sections are defined by a header tag marked by =====. # does not work as a tag.\nQuestion\rThe tag for defining the question is:\nQuestion\n========\nThe various random number generators in R will be your friend.\nsample() # pick n random number(s) from a vector of discrete numbers\rrunif() # generate a vector of continuous numbers, can set min and max\rrnorm() # generate a vector of continuous numbers from a normal distribution with a defined mean and standard deviation\rThings to note\r\rCode chunk options are in effect. By default figures will have captions, turn it of with fig.caption = \"\". Other useful figure options are figure sizes. Figure options can also be defined when compiling the exam\rYou can show code with echo = TRUE, turn off R formatting with results = \"asis\" \u0026amp; hide results with results = \"hide\"\rLaTeX formatting is fine in markdown and outside code chunks\rTo allow for randomised questions within a question file I had to escape the R code chunk to render the output as html, else the randomised question would be rendered as R output\rYou can generate a file to go with the question using any R write to file function. Include the file in the question as normal for Rmarkdown - [filename](filelink). Leave this as default or exams will not be able to find the file\r\r\r\rThe answer list\rThe answer subheading is defined by the tag:\nAnswer\n========\nBulleted markdown after this tag will be considered the options for an MCQ answer list.\nThings to note\r\rexams contains several helper functions to make it easy to generate lists of answers.\n\ranswerlist accepts a vector of answers. It also generates the answer subheading so there is no need to type it in.\rRecommend using html in case LaTeX does not render properly, particularly when called as a string in an R code chunk.\n\rDo not randomise the answer list here, use the metadata, else an incorrect answer will be assigned to be the correct one.\ncomment = NA in the code chunk options will remove the # from the R output.\n\rThere are also helper functions for various things. mchoice2string() turns the solutions vector above into binary responses for the meta-information section. num_to_choice generates a MCQ list of numbers for a numeric answer.\r\r\r\rSolution\rYou can provide feedback via the solution header, including which answers are correct\nSolution\n========\nYour solution here or correct answer: code for answer (or answer[])\nAnswerlist\n-‚Äî‚Äî‚Äî\n* True\n* False\n* etc.\n\rImportant There should be no spaces after the header tag title, i.e.¬†markdown formatting\n\r\rQuestion metainformation\rThis is an important section of the question because it defines the correct answer. Metainformation is defined by the tag:\nMeta-information\n================\nUseful variables are:\n\rexname = title of question, becomes name of the pool in blackboard\rextype = type of question (num/schoice/mchoice)\rexsolution: order of correct answers in binary (e.g.¬†01010) for MCQ or R code for numeric output - e.g.¬†\rextol = the tolerance range for numeric questions\rexshuffle = Whether to shuffle the answers or not. This can be used to randomly select a subset of answers from an answer list. Provide a number of answers for non-numeric questions (e.g.¬†4 for 4 answers). TRUE/FALSE is also accepted.\r\r\r\rAn example question\rThis example displays the correct answer and 3 randomly chosen option out of 6 possible answers.\nQuestion\r========\rWhat is your name?\r\\```{r question, results = \u0026quot;hide\u0026quot;, echo=F}\r# list of possible answer as a character vector\rknights_of_camelot \u0026lt;- c(\u0026quot;Arthur, King of the Britons\u0026quot;, \u0026quot;Sir Lancelot the Brave\u0026quot;,\r\u0026quot;Sir Robin the Not-Quite-So-Brave-as-Sir-Lancelot\u0026quot;,\r\u0026quot;Sir Galahad the Pure\u0026quot;,\r\u0026quot;Sir Bedevere the Wise\u0026quot;,\r\u0026quot;Patsy\u0026quot;)\r# solution to the vector above solutions \u0026lt;- c(FALSE, TRUE, FALSE, FALSE, FALSE, FALSE)\r# explanations (feedback for students)\rexplanations \u0026lt;- c(\u0026quot;I didn\u0026#39;t vote for him\u0026quot;,\r\u0026quot;His favourite colour is blue\u0026quot;,\r\u0026quot;He doesn\u0026#39;t know the capital of Assyria\u0026quot;,\r\u0026quot;His favourite colour is blue. No, yel...\u0026quot;,\r\u0026quot;Knows nothing about swallows\u0026quot;,\r\u0026quot;Clip Clop\u0026quot;)\r\\```\r\\```{r answerlist, echo=F, results = \u0026quot;asis\u0026quot;}\r# helper function to format the list of possible answers\ranswerlist(knights_of_camelot, markup = \u0026quot;markdown\u0026quot;)\r\\```\rSolution\r========\r\\```{r solutionlist, echo = FALSE, results = \u0026quot;asis\u0026quot;}\ranswerlist(ifelse(solultions, \u0026quot;True\u0026quot;, \u0026quot;False\u0026quot;), explanations, markup = \u0026quot;markdown\u0026quot;)\r\\```\rMeta-information\r================\rexname: Bridgekeeper\rextype: schoice\rexsolution: `\\r mchoice2string(solutions)`\rexshuffle: 4\r\rThis renders like this:\nExam 1\rQuestion\rWhat is your name?\rSir Bedevere the Wise\rArthur, King of the Britons\rSir Galahad the Pure\rSir Lancelot the Brave\rSolution\rFalse. Knows nothing about swallows\rFalse. I didn\u0026#39;t vote for him\rFalse. His favourite colour is blue. No, yel.\rTrue. His favourite colour is blue\rYou could also skip the solutions vector and include it in the explanations vector like c(\"False. I didn't vote for him\"). Of course, the solution does not appear immediately in blackboard but make sure the option for solutions and feedback to appear is checked.\n\rCompiling the exam\rI have written a script to compile the exam.\rThe compiling function (exams2blackboard) requires a list of file names to generate the exam. Each file represents a question. Versions of a question (n) generate a pool of questions. The list should not contain subdirectories or files not to be included in the exam. exams2html is a means of checking a file/list of exam questions renders properly in html (or exams2pdf).\nThere are several means of customising the metadata of the exam. Here I have:\n\rturned off partial marks - is TRUE by default\rused custom directories to search for the questions and save the output zip.\rset 10 copies for each question using the variable n\rset the name of the zip file using the variable name\rset the number of points for each question to 1, default = 10\r\rlibrary(\u0026quot;exams\u0026quot;)\roptions(device.ask.default = FALSE)\r## content and output directory\rmydir \u0026lt;- \u0026quot;C:/Users/kongj/OneDrive - TCDUD.onmicrosoft.com/Teaching/Biostats/Midsem MCQ\u0026quot;\r## define exam questions (each item in list is a pool)\rmyexam \u0026lt;- list.files(paste0(mydir,\u0026quot;/questions\u0026quot;), pattern = \u0026quot;.Rmd\u0026quot;)\r# render single question\r#exams2html(list(\u0026quot;question3.Rmd\u0026quot;), edir = paste0(mydir,\u0026quot;/questions\u0026quot;))\r## generate .zip with Blackboard exam with n replicates\rexams2blackboard(file = myexam, n = 10, name = \u0026#39;Jacinta\u0026#39;, dir = mydir,\redir = paste0(mydir,\u0026quot;/questions\u0026quot;),\reval = list(partial = FALSE, negative = FALSE),\rpoints = 1\r)\r\rThings to note\r\rYou can create a mix of questions in the exam by defining it in the list of questions but it is not recommended for generating pools of questions\rIf the exam is complied with no partial marks, then the blackboard exam will have no partial marks even if the option is checked within blackboard\rYou can generate a pool of questions by compiling a single question and uploading that zip file to Blackboard under ‚ÄúImport Pool‚Äù. This is useful for creating random block tests in Blackboard if the compiled zip file is not suitable as an test right away\r\r\r\r","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"5282367909d2d0b11aedadcd51872d29","permalink":"https://jacintak.github.io/teaching/rexams/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/teaching/rexams/","section":"teaching","summary":"Reproducible exams","tags":["teaching","R stats","code"],"title":"Quick guide to R/exams","type":"teaching"},{"authors":null,"categories":["code"],"content":"\r\rI‚Äôm not usually a dark background person but I‚Äôm open to the dark side. I wanted to make a solid coloured graph with a transparent background that would show up nicely but ggplot2 doesn‚Äôt have a set theme for that. A clean solid fill and transparency requires some specific customisation so here is a reproducible example for you using the built-in trees dataset:\ntree_graph \u0026lt;- ggplot(data = trees, mapping = aes(x = Height, y = Girth)) + geom_point(size = 0.5, colour = \u0026quot;#B8DE29FF\u0026quot;) + geom_smooth(method = \u0026quot;lm\u0026quot;, se = FALSE, col = \u0026quot;#B8DE29FF\u0026quot;) + geom_abline(intercept = 0, slope = 1, col = \u0026quot;white\u0026quot;, lwd = 0.5, lty = 2) + theme_classic() +\rtheme(plot.background = element_rect(fill = \u0026quot;transparent\u0026quot;, color = NA),\rpanel.background = element_rect(fill = \u0026quot;transparent\u0026quot;),\raxis.text = element_text(colour = \u0026quot;#B8DE29FF\u0026quot;, size = 8),\raxis.title = element_text(colour = \u0026quot;#B8DE29FF\u0026quot;, size = 8),\raxis.line = element_line(colour = \u0026quot;#B8DE29FF\u0026quot;),\raxis.ticks = element_line(colour = \u0026quot;#B8DE29FF\u0026quot;))\rggsave(tree_graph, filename = \u0026quot;tree_graph.png\u0026quot;, bg = \u0026quot;transparent\u0026quot;, type = \u0026quot;cairo\u0026quot;, width = 10, height = 10, dpi = 300)\rThere are a couple of generally useful elements added on purpose:\n\rgeom_smooth creates an automatically fitted linear model (defined using method = \"lm\"). I have turned off plotting the standard errors (on by default) and manually set the colour.\rgeom_abline is your standard straight line\rtheme is where the customisation begins:\r\rplot.background \u0026amp; panel.background are set to transparent\rThe various axis elements are set to the fill colour (a nice viridis green) and desired text size\r\rggsave specifies that the background is transparent and to save it using the Cairo engine (type = \"cairo\"). Cairo will create a vector based image so resizing the png isn‚Äôt an issue since the small font size is already defined.\r\rYou can also use cairo-png but the graph height and width options appear to be ignored.\rIf you don‚Äôt save it as a Cairo png, then the text will still have a white outline and won‚Äôt be a clean solid fill\r\r\r","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"1d72fb03f0dd36e9d9434e4189ad6b8e","permalink":"https://jacintak.github.io/post/2021-02-01-transparent-graphing-for-dark-backgrounds/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/post/2021-02-01-transparent-graphing-for-dark-backgrounds/","section":"post","summary":"Joining the dark side of ggplot","tags":["code","conference","talks","poster","R stats"],"title":"Transparent graphing for dark backgrounds","type":"post"},{"authors":["Jacinta Kong","J.-F. Arnoldi","A. L. Jackson","A. E. Bates","S. A. Morley","J. A. Smith \u0026 N. L. Payne"],"categories":null,"content":"","date":1610010000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610010000,"objectID":"2877c41b350b5b6527267dde2925bc80","permalink":"https://jacintak.github.io/talk/IEA2021/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/talk/IEA2021/","section":"talk","summary":"The Irish Ecological Association Conference","tags":["postdoc","conference","ectotherms","temperature"],"title":"IEA2021","type":"talk"},{"authors":null,"categories":null,"content":"\r\r\rTools for forcasting or predicting\rResources for forcasting\r\rMacroclimate\rMicroclimate\rMicroclimate simulation packages for R\r\rThings to consider\r\rTraits\r\rR packages for modelling\r\rNicheMapR, DEB \u0026amp; biophysical ecology\r\rInternational Symposium and Thematic School on DEB Theory for Metabolic Organisation\r\r\rTools for forcasting or predicting\rI am interested in developing a toolbox for biologists to make trait-based predictions or forecasts about how ectotherms respond to environmental change that are grounded in theory. Fostering stronger links between our understanding of terrestrial ectotherm thermal biology and the aquatic realm is important to identify general patterns.\n\rResources for forcasting\rA good model needs good input data!\nA pretty important component of modelling species responses to environmental variables are the environmental variables themselves. In fact, it‚Äôs already half the data. Ideally, you would have climatic data at the scale of the target organism, which I will generally refer to as microclimate, but this is often a challenge to acquire. But if you have access to climate data, e.g.¬†gridded weather stations which I will refer to as macroclimate, then there are some solutions for generating microclimate data.\nMost experimental biologists will have access to plenty of data on organism traits but may not have the right environmental data for a model. The good news is with the increasing ease of generating and storing big data, data is now more accessible than ever before!\nMacroclimate\rIf you don‚Äôt have access to gridded weather station data for your area of interest, there are some publicly available datasets online for various environmental variables at various scales and resolutions:\n\rWorldClim\rCliMond with CLIMEX and Bioclim datasets\rClimatic Research Unit\r\r\rMicroclimate\rThere are currently a few publicly available datasets of pre-calculated microclimate grids. All these examples were made using NicheMapR:\n\rmicrolim for global scale\rMicroclimOz for Australia only (the lucky country)\rMicroclimUS for USA\r\r\rMicroclimate simulation packages for R\rThere are a few packages for R to simulate microclimates from gridded macroclimate data:\n\rNicheMapR\rMicroclima\rTrenchR\r\rThe one I used in my work is NicheMapR. The default function to generate microclimate in NicheMapR uses the Climatic Research Unit dataset to generate default microclimate output. I used input data at a higher spatial and temporal resolution than the default setting, in addition to querying gridded soil type data. Although the input data to run my scripts is not available, NicheMapR was used to generate the microclim and MicroclimOz datasets which are publicly available under certain soil type parameters.\nThings to consider\rCheck if the environmental datasets are at the resolution and scale appropriate for your intended purposes. If you want to simulate microclimate, you need to make sure you have all the environmental variables needed for the microclimate package: temperature, precipitation, soil type, topography, wind speed, solar radiation etc. You may have to collate input data from multiple sources.\n\r\rTraits\rThere are even a few databases for organism trait data:\n\rThe Insect Developmental Database (IDD) contains temperature-rate data for mostly insect species of agricultural interest\rFor physiological limits GlobTherm is a great initiative but covers CtMax and CtMin only.\rA few recent metaanalyses have combed through the thermal biology literature so you don‚Äôt have to! Then you can extract the information you want. Isn‚Äôt open, reproducible science great? Here‚Äôs a recent example\rDell et al.¬†2013 complied a dataset on various biological/ecological traits measured at different tempertures for species from all habitats.\r\r\r\rR packages for modelling\rIn my PhD I wrote a custom function for my code to calculate development rate. But there is also a package for that!\ndevRate is a package with commonly used temperature-rate functions, from statistical functions to biophysical ones. You can get it from CRAN.\nThere is a similar package called rTPC. It‚Äôs not on CRAN but is available on GitHub.\nNicheMapR, DEB \u0026amp; biophysical ecology\rFortunately, the NicheMapR package is a pretty complete toolkit to model the biology of an organism based on its environment and available resources. Not only does it have a microclimate model but it also has an implementation of the standard DEB model and a biophysical heat and water budget model for ecotherms and endotherms. All that is missing are the correct input parameters.\nHeat and/or water budget equations are useful for calculating the body temperature of an organism but don‚Äôt measure growth or development. You could use the estimates of body temperture for calculating development/growth rates but for most small ectotherms that are isothermic, this seems a bit excessive.\nDEB parameters and Add-My-Pet\rYou can find standard DEB parameters at Add-My-Pet and there is a vignette in NicheMapR which goes through the ectotherm model, the DEB model and how to use the DEB parameters from Add-My-Pet in NicheMapR.\n\r\r\rInternational Symposium and Thematic School on DEB Theory for Metabolic Organisation\rInterested in learning Dynamic Energy Budget modelling? There is an international symposium, tele-course and school/workshop that is an intensive course in DEB and its applications. The symposium is held every two years. The most recent one was April 2019.\nWith the resources available you can pretty much develop a mechanistic model without collecting your own data.\nIf there are other useful datasets or links not listed here, let me know!\n\r","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"22846843e25e77b108339fefcfafa8e4","permalink":"https://jacintak.github.io/project/toolbox/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/toolbox/","section":"project","summary":"Forecasting the environmental physiology of ectotherms","tags":["ectotherms"],"title":"A toolbox for trait-based forecasting","type":"project"},{"authors":null,"categories":null,"content":"\r\rIntroduction\rbiostats.tutorials is an R package of learnr tutorials for introductory biostatistics and R at an undergraduate level.\nThe package is still in development so stay tuned for updates. You can checkout various tutorials about using R for NERD club (postgraduates and staff) at Trinity College Dublin here.\n\r","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"a63672db39b3f1207d056852b8d141d0","permalink":"https://jacintak.github.io/project/biostats-tutorials/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/biostats-tutorials/","section":"project","summary":"learnr tutorials for teaching undergraduate biostatistics","tags":["teaching","R stats","code"],"title":"Biostatistics tutorials","type":"project"},{"authors":[],"categories":[],"content":"\r\rWelcome to my revamped website!\rAfter banging my head against blogdown and Hugo on and off for several months (years), I think I understand enough about it to refresh my site. This has been my weekend coding hobby. It‚Äôs taken so long that the under-workings of Hugo and the Academic theme used here have changed in the meantime.\nSetting up a site is simple enough if you follow the instructions online. The template builds a skeleton of the website and all you need to do is replace the placeholder text with your information. Simple right?\nNot quite. The underlying file structure takes some getting used to and you‚Äôll have to trust the magic as your site gets compiled. But once you pass that hurdle, the system is quite powerful and the results are neat.\nThere are many features to take advantage of. My interest was in having one site for code documentation and blogging as I was not satisfied with having a ‚Äúregular‚Äù website (WordPress) with a blog and my code documentation separately on GitHub Pages.\nMy code documentation was also messing up my GitHub. I‚Äôm not a big fan of having documentation (e.g.¬†a static website) lumped together with package files. I also didn‚Äôt like having an orphan branch for my documentation (no winners here). I can take advantage of the features of Hugo to move my static sites off their respective repositories and into one central one. It‚Äôs better this way as some of the static pages weren‚Äôt even relevant to the rest of the repo.\nThere are some features that are missing/not easily implemented compared to WordPress that I will miss. You can‚Äôt comment (without third party systems) or ‚Äúfollow‚Äù people, you can‚Äôt schedule posts and you can‚Äôt track views unless you set up Google Analytics or similar. The workflow is a bit tedious for fixing minor things (like spelling mistakes).\nI will keep blog posts on the WordPress site as an archive. I have linked to relevant blog posts in this site.\nThere are some peculiarities that require things to be done a certain way:\nThings I noted\r\rI changed the name of the ‚ÄúPublic‚Äù folder to ‚Äúdocs‚Äù so that my site can be built from the ‚Äúdocs‚Äù folder on GitHub. This seems the simplest way to organise this. The alternative is to have the ‚ÄúPublic‚Äù folder on a different branch.\rSometimes it‚Äôs a challenge to troubleshoot why things aren‚Äôt working they way you want. E.g. I couldn‚Äôt work out why the country wouldn‚Äôt show up in the document when including an address in YAML\rA header image/thumbnail can be included in the same folder as the content but it must be called ‚Äúfeatured‚Äù or it won‚Äôt be recognised. File names are case-sensitive\rYou can have as many folders as you want called whatever but the (r)markdown file of the page must be called ‚Äúindex‚Äù\r\rIn the ‚ÄúCourses‚Äù feature the parent page must be called \"_index\" or it won‚Äôt work. ü§∑\r\rRmd and the ‚ÄúCourses‚Äù feature don‚Äôt play nicely. Defining a table of contents via bookdown outputs in the YAML doesn‚Äôt work and calling toc: true directly in the YAML (following the guide) doesn‚Äôt work either.\rbookdown and blogdown don‚Äôt play nicely together in the same project either. blogdown will try to render the bookdown pages as a site rather than letting bookdown do its thing and make a nice gitbook.\r\rTo allow this behaviour, you need to make use of the static file builder (See below)\r\rDespite the template saying ‚ÄúUpcoming talks‚Äù Hugo doesn‚Äôt render things in the future (incl blog posts). You need publishDate in the YAML\remojis are a nice feature üòÑ\r\r\rUsing the static folder to render a gitbook\rTo render rmd files into another output than blogdown::html_page you can put the rmd in the ‚Äústatic‚Äù folder then write a script that compiles the site in a specific order. To permit a gitbook page within the site:\nSave the bookdown files in the ‚Äústatic‚Äù folder\r\rIt doesn‚Äôt work with files in the ‚Äúcontent‚Äù folder, these will get the usual treatment\r\rCreate a folder called ‚ÄúR‚Äù in the root directory\rCreate an R script called ‚Äúbuild.R‚Äù in the ‚ÄúR‚Äù folder\rAdd the render functions you need.\r\rblogdown::build_dir(\"static\") is a wrapper for plain rmarkdown::render() as is so it works best with simple files\rbuild_dir doesn‚Äôt work for our gitbook example because we want a gitbook that knits with bookdown::render_book, otherwise you will get a bunch of HTML files from the standard render function\rThere‚Äôs something funny going on with the working directories. Running render_book(\"static/index.rmd\") doesn‚Äôt work, neither does the full address. Instead I had to change the working directory for the function to find the right files. I‚Äôm not sure where the function is looking as the project working directory is the root directory.\r\r\rThe above means that all the rmd files for the gitbook also get copied into the ‚Äúdocs‚Äù folder. I don‚Äôt think it‚Äôs avoidable. It‚Äôs also s l o w e r to build the site because the gitbook gets rendered every time (unless you ‚Äúcomment it off‚Äù in the build.R script.\nI also have a line to render my CV rmd into a PDF saved into the static folder. That PDF is then copied to the ‚Äúdocs‚Äù folder so I have an updated CV without needing to manually create one every time I update the original rmd. I think this is pretty handy.\nHere‚Äôs what my build.R file contains:\n# Make CV PDF\rrmarkdown::render(\u0026#39;content/cv/index.Rmd\u0026#39;, output_format = rmarkdown::pdf_document(keep_tex = FALSE), output_dir = \u0026quot;static/files/\u0026quot;, output_file = \u0026quot;Kong_JD_CV.pdf\u0026quot;)\r# make gitbook\r# blogdown::build_dir(\u0026quot;static\u0026quot;) doesn\u0026#39;t work because we want a gitbook that knits with render_book\r# whereas build_dir uses rmakrdown::render() thus giving html files\rold \u0026lt;- getwd()\rsetwd(\u0026quot;static/teaching/GLM/\u0026quot;)\rbookdown::clean_book(clean = TRUE)\rbookdown::render_book(input = \u0026quot;index.Rmd\u0026quot;)\rsetwd(old)\r\rHaving a drafts folder\rHugo will not render draft blog posts by default but blogdown will still render the files for your local site and these files get pushed to GitHub. If you don‚Äôt want your repo to contain spoilers, then you need to separate your draft posts from the published posts.\nOne solution to stop blogdown from rendering .rmd files is to keep them in the ‚Äústatic‚Äù folder but Hugo will copy these files to the ‚Äúpublic‚Äù (or ‚Äúdocs‚Äù folder in my case). I could not find an option to tell Hugo to ignore some files in the ‚Äústatic‚Äù folder. This does not solve our spoiler problem.\nWe can have a ‚Äúdraft‚Äù folder under ‚Äúcontent‚Äù and tell Hugo to ignore it in the config.toml file (ignorefile) but that doesn‚Äôt stop blogdown from rendering the file.\nI haven‚Äôt found a solution to stop blogdown from rendering and Hugo from copying the file but Hugo doesn‚Äôt add every folder from the root directory to ‚ÄúPublic‚Äù, only folders that match the template. So I have a folder called ‚Äúdrafts‚Äù which contains my drafts. blogdown will still render the files every time they are saved while using serve_site but they won‚Äôt interfere with the site itself. When I‚Äôm ready to publish them I can copy them to the ‚Äúcontent/post‚Äù folder. I also added the ‚Äúdrafts‚Äù folder to my .gitignore.\nblogdown has a handy function to generate a new blog post. By default it will add the new files to ‚Äúcontent/post‚Äù but I changed this to write directly to the ‚Äúdrafts‚Äù folder via the variable subdir and with a custom date that is used to name the folder:\nblogdown::new_post(ext = \u0026quot;.Rmd\u0026quot;, title = \u0026quot;test\u0026quot;, subdir = \u0026quot;../drafts/\u0026quot;, date = \u0026quot;2021-01-01\u0026quot;)\rblogdown does theoretically have a means of excluding files‚Ä¶\rIn blogdown::build_site there is a function (list_rmds) that lists files in the ‚Äúcontent‚Äù folder and excludes files beginning with _:\nfiles = files[!grepl(\u0026quot;^_\u0026quot;, basename(files)) | grepl(\u0026quot;^_index[.]\u0026quot;, basename(files))]\rBut you‚Äôll notice it doesn‚Äôt exclude files called _index without another ! in front of grepl. For example, if I have an file called _drafts.Rmd, then build_site will ignore it. But if I have a file called _index.Rmd, then build_site will render it. I don‚Äôt know what the behaviour of this is supposed to be so I‚Äôm not sure if it is a mistake.\nThis function is not present in preview_site which means that the live preview is going to build all your .Rmd files regardless and it will show up on the live preview.\nEither way, your drafts will still get pushed to GitHub unless you specify the files in .gitignore (e.g.¬†**/_*.Rmd) so I wouldn‚Äôt say using _ in your file names is an easier option.\n\r\rOther customisations via ‚Äúlayouts/partials‚Äù templates\rBecause Hugo copies any folder in the root directory into ‚Äúdocs‚Äù which matches the theme template, it will override any files in the ‚Äúthemes‚Äù folder that matches the name of the folder in the root directory. This means that you can create custom templates without modifying the original template. Thus, having a folder called ‚Äúlayouts/partials‚Äù will override any ‚Äúpartials‚Äù templates within the ‚Äútheme‚Äù folder.\nI have added some minor customisations to reflect personal preference:\n\rAdded markdown to the author list in page_metadata_authors.html so that I can customise my name and bold it in the list of authors under publications\rChanged the site footer to include blogdown\rChanged page_metadata.html to show both the last modified and published date. Last modified date is default.\r\r\rI‚Äôm not saying goodbye to the grasshoppers so my flavicon is a grasshopper emoji ü¶ó\n\r\r\r","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"80ce68f768381e67e27ecd2d3c2de49e","permalink":"https://jacintak.github.io/post/2021-01-01-new-year-new-look/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/post/2021-01-01-new-year-new-look/","section":"post","summary":"Welcome to my revamped website!","tags":["website","github","R stats"],"title":"New Year, New Look!","type":"post"},{"authors":null,"categories":null,"content":"Move. Adapt. Die. Ectotherms have adapted their entire life cycle to the rhythm of the seasons. The egg stage is a critical part of insect life cycles that must resist or tolerate environmental fluctuations. How immobile eggs do so and how these mechanisms change in their function or importance over geographical gradients is a complex story.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"a5ba6bdabb26526efa479d81b00aa22e","permalink":"https://jacintak.github.io/project/life-cycles/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/life-cycles/","section":"project","summary":"How are ectotherm life cycles adapted to seasonal climate cycles?","tags":["ectotherms","life cycles"],"title":"Predicting ectotherm life cycles","type":"project"},{"authors":null,"categories":null,"content":"Temperature affects biological processes on many levels of biological organisation. I am determining how the relationship between rates and temperatures affects processes beyond the individual and on macro scales.\nThis is an SFI funded position with Nicholas Payne\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4833c7bc854c275d509d55a420575619","permalink":"https://jacintak.github.io/project/temperature-dependence/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/temperature-dependence/","section":"project","summary":"Temperature affects biological processes on many levels of biological organisation","tags":["ectotherms","thermal adaptation"],"title":"Thermal dependence of biological rates","type":"project"},{"authors":[],"categories":[],"content":"\r\rI was recently featured on Humans of BioSciences, a series about the people of the School of Biosciences at the University of Melbourne (my alma mater).\nYou can read the Twitter thread and the full interview here.\n","date":1608163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"f218a3ba89a9ae200e942d523996c41b","permalink":"https://jacintak.github.io/post/2020-12-17-jacinta-humans-of-biosciences/","publishdate":"2020-12-17T00:00:00Z","relpermalink":"/post/2020-12-17-jacinta-humans-of-biosciences/","section":"post","summary":"Find out what I've been doing during a pandemic","tags":["PhD","postdoc"],"title":"Jacinta @ Humans of BioSciences","type":"post"},{"authors":["Jacinta Kong","A. A. Hoffmann","M. R. Kearney"],"categories":null,"content":"Abstract Insect life cycles are adapted to a seasonal climate by expressing alternative voltinism phenotypes‚Äîthe number of generations in a year. Variation in voltinism phenotypes along latitudinal gradients may be generated by developmental traits at critical life stages, such as eggs. Both voltinism and egg development are thermally determined traits, yet independently derived models of voltinism and thermal adaptation refer to the evolution of dormancy and thermal sensitivity of development rate, respectively, as independent influences on life history. To reconcile these models and test their respective predictions, we characterized patterns of voltinism and thermal response of egg development rate along a latitudinal temperature gradient using the matchstick grasshopper genus Warramaba. We found remarkably strong variation in voltinism patterns, as well as corresponding egg dormancy patterns and thermal responses of egg development. Our results show that the switch in voltinism along the latitudinal gradient was explained by the combined predictions of the evolution of voltinism and of thermal adaptation. We suggest that latitudinal patterns in thermal responses and corresponding life histories need to consider the evolution of thermal response curves within the context of seasonal temperature cycles rather than based solely on optimality and trade-offs in performance. This article is part of the theme issue ‚ÄòPhysiological diversity, biodiversity patterns and global climate change: testing key hypotheses involving temperature and oxygen‚Äô.\n","date":1548892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548892800,"objectID":"42bd2b0f81290fb0ceae73a15db1c4ff","permalink":"https://jacintak.github.io/publication/2019-PTRSB/","publishdate":"2019-01-31T00:00:00Z","relpermalink":"/publication/2019-PTRSB/","section":"publication","summary":"Abstract Insect life cycles are adapted to a seasonal climate by expressing alternative voltinism phenotypes‚Äîthe number of generations in a year. Variation in voltinism phenotypes along latitudinal gradients may be generated by developmental traits at critical life stages, such as eggs. Both voltinism and egg development are thermally determined traits, yet independently derived models of voltinism and thermal adaptation refer to the evolution of dormancy and thermal sensitivity of development rate, respectively, as independent influences on life history.","tags":["ectotherms","thermal adaptation","thermal response","life history"],"title":"Linking thermal adaptation and life-history theory explains latitudinal patterns of voltinism","type":"publication"},{"authors":["M. R. Kearney","J. Deutscher","Jacinta Kong","A. A. Hoffmann"],"categories":null,"content":"Abstract The phenological response is among the most important traits affecting a species' sensitivity to climate. In insects, strongly seasonal environments often select for a univoltine life-cycle such that one seasonal extreme is avoided as an inactive stage. Through understanding the underlying mechanisms for univoltinism, and the consequences of its failure, we can better predict insect responses to climate change. Here we combine empirical data and simulation studies to investigate the consequences of an unusual diapause mechanism in a parthenogenetic matchstick grasshopper, Warramaba virgo, from arid southern Australia. Our field body temperature measurements indicate that this species is a thermoconformer and our laboratory studies of the thermal response of feeding rate imply strong constraints on winter activity. However, the species exhibits no obligate winter diapause, and eggs can develop in one month under constant temperatures approximating the mean soil temperature at the time of oviposition (summer). We show that diurnal temperature cycles exceeding a peak of 36 degrees C inhibit egg development in summer, and that this is sufficient to prevent autumnal hatching of eggs. Development is also strongly retarded below 24 degrees C. Microclimate-driven simulation studies of egg development show that these thermal responses provide robust maintenance of a univoltine life cycle, thereby resulting in survival of heat stress as an egg (due to limited developmental state) and avoidance of cold stress as a nymph and adult (due to overwintering in the soil as an egg). This article is protected by copyright. All rights reserved.\n","date":1520899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520899200,"objectID":"31372bb950c3acadf4ead569bb0179e8","permalink":"https://jacintak.github.io/publication/2018-inte-zool/","publishdate":"2018-03-13T00:00:00Z","relpermalink":"/publication/2018-inte-zool/","section":"publication","summary":"Abstract The phenological response is among the most important traits affecting a species' sensitivity to climate. In insects, strongly seasonal environments often select for a univoltine life-cycle such that one seasonal extreme is avoided as an inactive stage. Through understanding the underlying mechanisms for univoltinism, and the consequences of its failure, we can better predict insect responses to climate change. Here we combine empirical data and simulation studies to investigate the consequences of an unusual diapause mechanism in a parthenogenetic matchstick grasshopper, Warramaba virgo, from arid southern Australia.","tags":["ectotherms","thermal adaptation","life cycles","microclimate","mechanistic models"],"title":"Summer egg diapause in a matchstick grasshopper synchronises the life cycle and buffers thermal extremes","type":"publication"},{"authors":["J. L. Maino","Jacinta Kong","A. A. Hoffmann","M. G. Barton","M. R. Kearney."],"categories":null,"content":"Abstract Mechanistic models of the impacts of climate change on insects can be seen as very specific hypotheses about the connections between microclimate, ecophysiology and vital rates. These models must adequately capture stage-specific responses, carry-over effects between successive stages, and the evolutionary potential of the functional traits involved in complex insect life-cycles. Here we highlight key considerations for current approaches to mechanistic modelling of insect responses to climate change. We illustrate these considerations within a general mechanistic framework incorporating the thermodynamic linkages between microclimate and heat, water and nutrient exchange throughout the life-cycle under different climate scenarios. We emphasise how such a holistic perspective will provide increasingly robust insights into how insects adapt and respond to changing climates.\n","date":1476144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476144000,"objectID":"3d90d66f6179b68b1be5bd8594f7add1","permalink":"https://jacintak.github.io/publication/2016-COIS/","publishdate":"2016-10-11T00:00:00Z","relpermalink":"/publication/2016-COIS/","section":"publication","summary":"Abstract Mechanistic models of the impacts of climate change on insects can be seen as very specific hypotheses about the connections between microclimate, ecophysiology and vital rates. These models must adequately capture stage-specific responses, carry-over effects between successive stages, and the evolutionary potential of the functional traits involved in complex insect life-cycles. Here we highlight key considerations for current approaches to mechanistic modelling of insect responses to climate change. We illustrate these considerations within a general mechanistic framework incorporating the thermodynamic linkages between microclimate and heat, water and nutrient exchange throughout the life-cycle under different climate scenarios.","tags":["ectotherms","thermal adaptation","life cycles","microclimate","mechanistic models"],"title":"Mechanistic models for predicting insect responses to climate change","type":"publication"},{"authors":["Jacinta Kong","J. K. Axford","A. A. Hoffmann","M. R. Kearney"],"categories":null,"content":"Abstract   High-throughput genomic methods are increasingly used to investigate invertebrate thermal responses with greater dimensionality and resolution than previously achieved. However, corresponding methods for characterizing invertebrate phenotypes are still lacking. To scale up the characterization of invertebrate thermal responses, we propose a novel use of thermocyclers as temperature-controlled incubators.\n  Here, we tested the performance of thermocyclers as incubators and demonstrated the application of this method to efficiently characterize the thermal responses of model and non-model invertebrates.\n  We found the thermocyclers performed with high precision, accuracy and resolution under various and fluctuating ambient conditions. We were able to successfully characterize the temperature-dependent development of grasshopper eggs (Warramaba virgo), as well as the effects of fluctuating temperature cycles on the survival of mosquito eggs (Aedes aegypti) and developmental success of Drosophila simulans larvae, all with similar survival rates to conventional methods.\n  Thermocyclers are a general and transferrable means to scale up current methods of incubating small invertebrates. They permit rapid characterization of high-dimensional physiological responses to natural thermal regimes. When combined with existing approaches in thermal and evolutionary biology, these methods will advance our understanding of, and ability to predict, biological adaptations and responses to environmental changes.\n  ","date":1462924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462924800,"objectID":"51c065cdd0243c50c8f0d0926b444014","permalink":"https://jacintak.github.io/publication/2016-MEE/","publishdate":"2016-05-11T00:00:00Z","relpermalink":"/publication/2016-MEE/","section":"publication","summary":"Abstract   High-throughput genomic methods are increasingly used to investigate invertebrate thermal responses with greater dimensionality and resolution than previously achieved. However, corresponding methods for characterizing invertebrate phenotypes are still lacking. To scale up the characterization of invertebrate thermal responses, we propose a novel use of thermocyclers as temperature-controlled incubators.\n  Here, we tested the performance of thermocyclers as incubators and demonstrated the application of this method to efficiently characterize the thermal responses of model and non-model invertebrates.","tags":["ectotherms","thermal adaptation","thermal response"],"title":"Novel applications of thermocyclers for phenotyping invertebrate thermal responses","type":"publication"},{"authors":null,"categories":null,"content":"\r\r\rResearch and teaching appointments\rQualifications\rRefereed journal articles\rResearch highlights\rResearch grants or awards\r\rOther Awards and Scholarships\r\rTeaching contributions and course development\rConference presentations and invited talks\rProfessional service and affiliations\rProfessional development qualifications\rCommunity outreach and communication\r\r\rLast updated 14 October 2021\nResearch and teaching appointments\r\rTeaching and Research Fellow\nDepartment of Zoology, School of Natural Sciences.\nTrinity College Dublin, Dublin, Ireland\n5.2019 ‚Äì Present\rResearch Assistant\nIntraspecific variation in mechanistic species distribution modelling,\nThe University of Melbourne, Australia\n5.2018 ‚Äì 12.2018\rComparative Animal Physiology tutor (Second Year undergraduate)\nSchool of BioSciences, the University of Melbourne, Australia\n2017‚Äì 2018\rEcology in Changing Environments tutor (Third Year undergraduate)\nSchool of BioSciences, the University of Melbourne, Australia\n2016‚Äì 2018\rComparative Animal Physiology residential tutor,\nUniversity College, the University of Melbourne, Australia\n2017‚Äì 2018\rFirst Year Chemistry residential tutor\nSt John‚Äôs College, the University of Queensland Australia\n8.2014 ‚Äì 10.2014\rFirst Year Biology tutor (Science Learning Centre tutor),\nthe Faculty of Science, the University of Queensland, Australia\n2012\rPeer Assisted Study Session leader: first year statistics\nThe Peer Assisted Study Session office and the School of Mathematics and Physics, the University of Queensland Australia\n8.2012 ‚Äì 10.2012\rPeer Assisted Study Session leader: first year ecology\nThe Peer Assisted Study Session office, the University of Queensland Australia\n2011 ‚Äì 2012\rVolunteer laboratory technician. Animal husbandry.\nWhite Evolutionary Physiology Laboratory, the University of Queensland\n3.2012 ‚Äì 10.2012\r\r\rQualifications\rDoctor of Philosophy (Science)\nThe University of Melbourne, Australia\nTitle: Predicting ectotherm life cycles under a variable climate: Physiological diversity of matchstick grasshopper eggs and their ecological and evolutionary implications\nRepository access: http://hdl.handle.net/11343/225704\n1.2015 ‚Äì completed 14 Aug 2019, conferred 5.10.2020\nBachelor of Science (Honours Class I, University Medal)\nThe University of Queensland, Australia\nTitle: The effect of temperature on the relationship between metabolic rate and mass: Tests of the Metabolic Theory of Ecology\nConferred 6.12.2013\nBachelor of Science\nThe University of Queensland, Australia\nConferred 17.12.2012\n\rRefereed journal articles\r\rKong JD, Hoffmann AA, Kearney MR. (2019) Linking thermal adaptation and life-history theory explains latitudinal patterns of voltinism. Philosophical Transactions of the Royal Society B: Biological Sciences. 374(1778). DOI: 10.1098/rstb.2018.0547. Altmetric score: 7\rKearney MR, Deutscher J, Kong JD, Hoffmann AA. (2018) Summer egg diapause in a matchstick grasshopper synchronises the life cycle and buffers thermal extremes. Integrative Zoology. 13(4): 437‚Äì449. DOI: 10.1111/1749-4877.12314\rMaino JL, Kong JD, Hoffmann AA, Barton MG, Kearney MR. (2016) Mechanistic models for predicting insect responses to climate change. Current Opinion in Insect Science. 17: 81 ‚Äì 86. DOI: 10.1016/j.cois.2016.07.006\rKong JD, Axford JK, Hoffmann AA, Kearney MR. (2016) Novel applications of thermocyclers for phenotyping invertebrate thermal responses. Methods in Ecology and Evolution. 7(10): 1201 ‚Äì 1208. 2016. DOI: 10.1111/2041-210X.12589\r\r\rResearch highlights\rORCID\nGoogle scholar\nH-index: 4 (GS)\nTotal citations: 68\n\r\rEcology/evolution studies in some of the best journals in their respective disciplines, including Methods in Ecology and Evolution and Philosophical Transactions of the Royal Society B\n\rMethods in Ecology and Evolution video explaining the use of thermocyclers as efficient incubators [see 1 above]. Altmetric score: 21\n\rInfluential paper on the use of mechanistic species distribution modelling for predicting ectotherm responses to climate change in Current Opinion in Insect Science [see above]. Altmetric score: 6\r\r\rI have peer reviewed for:\n\rGlobal Change Biology\rEntomologia Experimentalis et Applicata\rMethods in Ecology and Evolution\rNature Ecology and Evolution\rEcological Entomology\rThe Canadian Entomologist\rEnvironmental Entomology\rJournal of Fish Biology\rCurrent Zoology\rScientific Reports\rConservation Physiology\rAmerican Naturalist\rFunctional Ecology\r\r\rResearch grants or awards\rTOTAL: $13 750 AUD üá¶üá∫\n\r$2 500 AUD. 6.2018 Holsworth Wildlife Research Endowment\nEquity Trustees Charitable Foundation \u0026amp; the Ecological Society of Australia\r$300 AUD. 12.2018 2nd runner up student presentation\nAustralian and New Zealand Society for Comparative Physiology and Biochemistry, Australia\r$500 AUD. 8.2018 Student Travel Grant\nAustralian Entomological Society, Australia\r$1 500 AUD. 2018 Science Abroad Travelling Scholarship\nFaculty of Science, the University of Melbourne, Australia\r$950 AUD. 2018 FH Drummond Travel Award\nSchool of BioSciences, the University of Melbourne, Australia\r$1 500 AUD. 2018 School of BioSciences Travelling Scholarship\nSchool of BioSciences, the University of Melbourne, Australia\r$6 000 AUD. 6.2018 Holsworth Wildlife Research Endowment\nEquity Trustees Charitable Foundation\r$500 AUD. 6.2018 Three Minute Thesis (3MT) People‚Äôs Choice Winner\nThe University of Queensland Undergraduate Research Conference\r\rOther Awards and Scholarships\r\r$13 541 AUD. 2018 Research Training Program Scholarship, Australian Government\r$26 682 AUD. 2017 Research Training Program Scholarship, Australian Government\r$200 AUD. 2017 Runners-up in the Sustainability Prize photo competition, Graduate Student Association, the University of Melbourne\r$26 288 AUD. 2016 Australian Postgraduate Award, Australian Government\r$25 849 AUD. 2015 Australian Postgraduate Award, Australian Government\r2014 University Medal 2013, the University of Queensland, Australia\r2010 ‚Äì 2013 Dean‚Äôs Commendation for Academic Excellence (formerly Dean‚Äôs Commendation for High Achievement), the Faculty of Science, the University of Queensland, Australia\r\r\r\rTeaching contributions and course development\rTrinity College Dublin implements a 4 year degree program with 2 years of general subjects (e.g.¬†biological sciences stream, ~250 students) and 2 years towards a specific major (e.g.¬†zoology, ~ 35 students). Total of 60 credits per year. Degree consists of mandatory core subjects and electives.\n2021\n\rLecturer \u0026amp; course development: Statistics and computation for biologists (BYU22S01). 2nd year undergraduate core subject, 5 credits. Trinity College Dublin. Developed course lectures and practical material, implemented novel R packages for interactive teaching within the R environment (learnr package). Hybrid delivery: remote and in-person lectures \u0026amp; remote and in-person practicals.\rLecturer \u0026amp; course development: Animal Diversity I (ZOU330003). 3rd year undergraduate, core zoology major subject, 5 credits. Trinity College Dublin. Developed course lectures and practical material. Module co-coordinator. Hybrid delivery: remote lectures \u0026amp; in-person practicals.\rLecturer \u0026amp; course development: Animal Diversity II (ZOU330004). 3rd year undergraduate, core zoology major subject, 5 credits. Trinity College Dublin. Developed course lectures and practical material. Hybrid delivery: remote lectures \u0026amp; in-person practicals.\r\r2020\n\rLecturer \u0026amp; course development: Statistics and computation for biologists (BYU22S01). 2nd year undergraduate. Trinity College Dublin. Developed course lectures and practical material, implemented reproducible workflow for online exams. Adapted for remote delivery. Module co-ordinator.\rLecturer \u0026amp; course development: Animal Diversity I (ZOU330003). 3rd year undergraduate. Trinity College Dublin. Developed course lectures and practical material. Module co-coordinator. Adapted for remote delivery.\rLecturer \u0026amp; course development: Animal Diversity II (ZOU330004). 3rd year undergraduate. Trinity College Dublin. Developed course lectures and practical material. Adapted for remote delivery.\r\r2019\n\rLecturer \u0026amp; course development: Statistics and computation for biologists (BYU22S01). 2nd year undergraduate. Trinity College Dublin. Developed course lectures and practical material, implemented reproducible workflow for online exams.\rLecturer \u0026amp; course development: Animal Diversity I (ZOU330003). 3rd year undergraduate. Trinity College Dublin. Developed course lectures and practical material. Acting module co-coordinator.\rLecturer \u0026amp; course development: Animal Diversity II (ZOU330004). 3rd year undergraduate. Trinity College Dublin. Developed course lectures and practical material.\r\r2017\n\rGuest lecturer: 2nd year Comparative Animal Physiology, University of Melbourne\rCourse development: 2nd year Biostatistics, University of Melbourne. Evaluated course context and provided feedback.\r\r2016\n\rGuest lecturer: 2nd year Comparative Animal Physiology, University of Melbourne\r\r\rConference presentations and invited talks\r2021\n\rEnergetic turnover explains the inflexibility of upper thermal tolerances in ectotherms. Irish Ecological Association Meeting, University College Cork, Ireland (online)\rEctotherm heat limits track biological rates. British Ecological Society Macroecology Special Interest Group meeting (online)\rThermal adaptation and plasticity of egg development generates latitudinal patterns in insect life cycles under seasonal climates. Society for Experimental Biology Annual Meeting (online)\r\r2019\n\rDetangling the complex problem of climate adaptation of insects living in a seasonal world. Victorian Biodiversity Conference, University of Melbourne, VIC, Australia\rLocal adaptation of thermal responses generates voltinism patterns of matchstick grasshoppers, Warramaba (Orthoptera: Morabidae), along a latitudinal gradient. British Ecological Society Annual Meeting, Belfast, N. Ireland, UK\r\r2018\n\rSelection against overwintering shapes thermal performance curves for development. Australian and New Zealand Society for Comparative Physiology and Biochemistry Conference, Monash University, VIC, Australia\rEnvironmental and developmental drivers at the egg stage generate divergent life cycles in wingless arid zone grasshoppers (Orthoptera: Warramaba). Australian Entomological Society Conference, Alice Springs, N.T., Australia\rThe egg stage drives life cycle adaptation to climate in the widely distributed matchstick grasshoppers (Vandiemenella and Warramaba, Orthoptera: Morabidae). ‚ÄòThe height, breadth and depth of physiological diversity: variation across latitudinal, altitudinal and depth gradients‚Äô Animal Biology Satellite Meeting, Florence, Italy, Society for Experimental Biology\rMicroclimate-driven mechanistic models to examine clinal adaptation at the egg stage in a parthenogenetic grasshopper. Society for Experimental Biology Annual Conference, Florence, Italy\r\r2017\n\rDoes variation in egg developmental responses to temperature generate divergent life-cycles in a genus of flightless grasshoppers (Warramaba spp.)? School of BioSciences Postgraduate Symposium, the University of Melbourne, Parkville, Australia\rEgg development drives life cycles in Warramaba spp. grasshoppers. Australian and New Zealand Society for Comparative Physiology and Biochemistry Conference, Daintree Rainforest Observatory, QLD, Australia\rMechanistic models for understanding and predicting insect responses to climate change. Australian Entomological Society Conference, Terrigal, N.S.W., Australia\r\r2016\n\rPredicting insect egg development under variable climates. School of BioSciences Postgraduate Symposium, the University of Melbourne, Parkville, Australia\rPredicting egg development in the parthenogenetic grasshopper Warramaba virgo (Orthoptera: Morabidae). Australian and New Zealand Society for Comparative Physiology and Biochemistry Conference, Western Sydney University, N.S.W., Australia\r\r2015\n\rNovel applications of thermocyclers for high-throughput phenotyping of invertebrate thermal response. Australian and New Zealand Society for Comparative Physiology and Biochemistry Conference, Fowler‚Äôs Gap, N.S.W., Australia\r\r2013\n\rEvery Breath You Take Links Metabolism and Ecology\rThree Minute Thesis, Undergraduate Research Conference, the University of Queensland, Australia The University of Queensland\rEvery Breath You Take Links Metabolism and Ecology. Summer Research Introduction Session 2013, invited by the Office of Undergraduate Education, the University of Queensland, Australia\rFlying foxes and you: Exploring the exposure of society to so-called ‚Äúrats with wings‚Äù\rBachelor of Science Welcome Day, invited by the Faculty of Science, the University of Queensland, Australia\r\r2012\n\rFlying foxes and you: Exploring the exposure of society to so-called ‚Äúrats with wings‚Äù\rAdvanced Study Program in Science Student Conference, the University of Queensland, Australia\r\r2011\n\rFemale-biased dispersal in the Eastern Water Dragon (Physignathus lesueurii lesueurii)\rAdvanced Study Program in Science Student Conference, the University of Queensland, Australia\r\r\rProfessional service and affiliations\r\r2015 ‚Äì Present Member: Australian and New Zealand Society for Comparative Physiology and Biochemistry (ANZSCPB)\r2019 ‚Äì Present Member: British Ecological Society (BES) \u0026amp; Irish Ecological Association (IEA)\r2018 Member: Royal Society of Victoria (RSV)\r2017 ‚Äì Present Member: Society for Experimental Biology (SEB)\r2015 ‚Äì 2020 Member: Australian Entomological Society (AES)\r2019 ‚Äì 2020 Member: European Society for Evolutionary Biology (ESEB)\r2017 ‚Äì 2018 President, BioSciences Postgraduate Society, the University of Melbourne\r2016 ‚Äì 2017 Vice President, BioSciences Postgraduate Society, the University of Melbourne\r\r\rProfessional development qualifications\r\r26/01/2021 Epigeum Research Integrity Course\r19/03/2021 Dynamic Energy Budget Course\r\r\rCommunity outreach and communication\r2021\n\rContributor to the Trinity Walton Club STEM@Universi-TY program, Trinity College Dublin\rMentor for Irish Ecological Association mentoring meeting. 7th January\rThe Socio-Economic Theory of Animal Abundance. April Fools blog post for EcoEvo@TCD. 1st April\r\r2020\n\rProfiled on Humans of BioSciences by the School of BioSciences, the University of Melbourne, Australia. Website \u0026amp; Twitter. 17th December\rGuest interview with Newstalk radio, Ireland. 14th January\r\r2019\n\rMentor for BES Women in Science Mentoring Program\rHome and Away: 3 part blog series for EcoEvo@TCD\r\rHome and Away: Would a Rosella by any other name smell as sweet (online 1 Nov)\rHome and Away: Monotreme mistakes (online 22 Nov)\rHome and Away: Australian expats (online 12 Dec)\r\rVictorian Biodiversity Conference Volunteer, Melbourne, Australia\r\r2018\n\rBig Ideas in Macrophysiology. Report on the 2018 Animal Biology Satellite Meeting, Florence Italy. Society for Experimental Biology Magazine\rThe University of Melbourne Open Day Volunteer, the University of Melbourne, Melbourne, Australia\r\r2017\n\rThe University of Melbourne Open Day Volunteer, the University of Melbourne, Melbourne, Australia\rSession Chair, BioSciences Postgrad Symposium, the University of Melbourne, Australia\rVictorian Biodiversity Conference Volunteer, Melbourne, Australia\rBlog post for Graduate Student Association, University of Melbourne on the biodiversity photo competition\r\r2016\n\rSession Chair, BioSciences Postgrad Symposium, the University of Melbourne, Australia\rNovel applications of thermocyclers for characterising invertebrate thermal responses. Video for Methods in Ecology and Evolution\r\r2015\n\rThe University of Melbourne Open Day Volunteer, the University of Melbourne, Melbourne, Australia\rThe Real Life of a Research Student. Science Undergraduate Research Journal (SURJ), Issue 2. The University of Queensland, Australia\rJacinta on Zoology \u0026amp; Research. Interview with BITE BACK, Black Dog Institute, Australia. 31st August. Link likely broken\r\r2014\n\rBrisbane Open House Volunteer, Brisbane Open House, Brisbane, Australia\rStudent Chaperone for the International Baccalaureate World Student Conference, the University of Queensland, Australia\rMoreton Bay Research Station Open Day Assistant, Moreton Bay Research Station, Brisbane, Australia\r\r2013\n\rScience Mentor to Science Undergraduate Students, appointed by the Faculty of Science, the University of Queensland, Australia\r\r2012\n\rMoreton Bay Research Station Open Day Assistant, Moreton Bay Research Station, Brisbane, Australia\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9780949a3024bbdfdb7ce88dfaa4afe3","permalink":"https://jacintak.github.io/CV/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/CV/","section":"","summary":"Research and teaching appointments\rQualifications\rRefereed journal articles\rResearch highlights\rResearch grants or awards\r\rOther Awards and Scholarships\r\rTeaching contributions and course development\rConference presentations and invited talks\rProfessional service and affiliations\rProfessional development qualifications\rCommunity outreach and communication\r\r\rLast updated 14 October 2021\nResearch and teaching appointments\r\rTeaching and Research Fellow\nDepartment of Zoology, School of Natural Sciences.\nTrinity College Dublin, Dublin, Ireland","tags":null,"title":"CV","type":"page"}]